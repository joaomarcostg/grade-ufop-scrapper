{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaomarcostorresgardingo/grade-ufop-scrapper/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (4.65.0)\n",
      "Requirement already satisfied: sqlalchemy in ./venv/lib/python3.9/site-packages (2.0.19)\n",
      "Requirement already satisfied: tabula-py in ./venv/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: psycopg2-binary in ./venv/lib/python3.9/site-packages (2.9.6)\n",
      "Requirement already satisfied: lxml in ./venv/lib/python3.9/site-packages (4.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./venv/lib/python3.9/site-packages (from sqlalchemy) (4.7.1)\n",
      "Requirement already satisfied: pandas>=0.25.3 in ./venv/lib/python3.9/site-packages (from tabula-py) (2.0.3)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (from tabula-py) (1.25.1)\n",
      "Requirement already satisfied: distro in ./venv/lib/python3.9/site-packages (from tabula-py) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.9/site-packages (from pandas>=0.25.3->tabula-py) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.9/site-packages (from pandas>=0.25.3->tabula-py) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup \n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "%pip install tqdm sqlalchemy tabula-py psycopg2-binary lxml\n",
    "\n",
    "\n",
    "\n",
    "# Create the \"tables\" folder if it doesn't exist\n",
    "tables_folder_path = \"./tables\"\n",
    "if not os.path.exists(tables_folder_path):\n",
    "    os.makedirs(tables_folder_path)\n",
    "\n",
    "\n",
    "# Create the \"matrizes\" folder if it doesn't exist\n",
    "pdfs_folder_path = \"./courses_pdfs\"\n",
    "if not os.path.exists(pdfs_folder_path):\n",
    "    os.makedirs(pdfs_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['department', 'discipline', 'discipline_course', 'course', 'discipline_class', 'discipline_class_schedule', 'prerequisite']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "db_name = 'gradeufop_db'\n",
    "username = 'postgres'\n",
    "password = '12345678'\n",
    "\n",
    "# Replace 'localhost' with the appropriate host if your PostgreSQL server is running on a different machine\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "\n",
    "# Create a connection to the PostgreSQL database\n",
    "conn_str = f\"postgresql://{username}:{password}@{host}:{port}/{db_name}\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# create inspector\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# get table names\n",
    "table_names = inspector.get_table_names()\n",
    "print(table_names)\n",
    "\n",
    "# initialize an empty dictionary to hold the data\n",
    "existing_data = {}\n",
    "\n",
    "# iterate over all table names\n",
    "for table in table_names:\n",
    "    # read the data from the table and save it to the dictionary\n",
    "    existing_data[table] = pd.read_sql(f'SELECT * FROM {table}', engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def format_course_name(text):\n",
    "    # Remove accent marks\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "    \n",
    "    # Replace symbols with a hyphen\n",
    "    text = re.sub(r'[^a-zA-Z0-9]+', '-', text)\n",
    "    \n",
    "    # Remove leading and trailing hyphens\n",
    "    text = text.strip('-')\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busca cursos e salva os .pdfs na pasta /matrizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando os links .pdf ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progresso: 100%|##########| 44/44 [00:46<00:00,  1.06s/it, curso=Turismo]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "administracao.pdf já existe no diretório. Pulando...\n",
      "administracao-publica.pdf já existe no diretório. Pulando...\n",
      "administracao-publica-ead.pdf já existe no diretório. Pulando...\n",
      "arquitetura-e-urbanismo.pdf já existe no diretório. Pulando...\n",
      "artes-cenicas-bacharelado.pdf já existe no diretório. Pulando...\n",
      "artes-cenicas-licenciatura.pdf já existe no diretório. Pulando...\n",
      "ciencia-da-computacao.pdf já existe no diretório. Pulando...\n",
      "ciencia-e-tecnologia-de-alimentos.pdf já existe no diretório. Pulando...\n",
      "ciencias-biologicas-bacharelado.pdf já existe no diretório. Pulando...\n",
      "ciencias-biologicas-licenciatura.pdf já existe no diretório. Pulando...\n",
      "ciencias-economicas.pdf já existe no diretório. Pulando...\n",
      "direito.pdf já existe no diretório. Pulando...\n",
      "educacao-fisica-bacharelado.pdf já existe no diretório. Pulando...\n",
      "educacao-fisica-licenciatura.pdf já existe no diretório. Pulando...\n",
      "engenharia-ambiental.pdf já existe no diretório. Pulando...\n",
      "engenharia-civil.pdf já existe no diretório. Pulando...\n",
      "engenharia-de-computacao.pdf já existe no diretório. Pulando...\n",
      "engenharia-de-controle-e-automacao.pdf já existe no diretório. Pulando...\n",
      "engenharia-de-minas.pdf já existe no diretório. Pulando...\n",
      "engenharia-de-producao-jm.pdf já existe no diretório. Pulando...\n",
      "engenharia-de-producao-op.pdf já existe no diretório. Pulando...\n",
      "engenharia-eletrica.pdf já existe no diretório. Pulando...\n",
      "engenharia-geologica.pdf já existe no diretório. Pulando...\n",
      "engenharia-mecanica.pdf já existe no diretório. Pulando...\n",
      "engenharia-metalurgica.pdf já existe no diretório. Pulando...\n",
      "engenharia-urbana.pdf já existe no diretório. Pulando...\n",
      "estatistica.pdf já existe no diretório. Pulando...\n",
      "farmacia.pdf já existe no diretório. Pulando...\n",
      "filosofia-bacharelado.pdf já existe no diretório. Pulando...\n",
      "filosofia-licenciatura.pdf já existe no diretório. Pulando...\n",
      "fisica-bacharelado.pdf já existe no diretório. Pulando...\n",
      "fisica-licenciatura.pdf já existe no diretório. Pulando...\n",
      "geografia-ead.pdf já existe no diretório. Pulando...\n",
      "historia-bacharelado.pdf já existe no diretório. Pulando...\n",
      "historia-licenciatura.pdf já existe no diretório. Pulando...\n",
      "jornalismo.pdf já existe no diretório. Pulando...\n",
      "matematica-ead.pdf já existe no diretório. Pulando...\n",
      "medicina.pdf já existe no diretório. Pulando...\n",
      "museologia.pdf já existe no diretório. Pulando...\n",
      "musica.pdf já existe no diretório. Pulando...\n",
      "nutricao.pdf já existe no diretório. Pulando...\n",
      "pedagogia.pdf já existe no diretório. Pulando...\n",
      "pedagogia-ead.pdf já existe no diretório. Pulando...\n",
      "quimica.pdf já existe no diretório. Pulando...\n",
      "quimica-industrial.pdf já existe no diretório. Pulando...\n",
      "servico-social.pdf já existe no diretório. Pulando...\n",
      "sistemas-de-informacao.pdf já existe no diretório. Pulando...\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "# Set up Chrome driver service\n",
    "chromedriver_path = (\n",
    "    \"./chromedriver\"  # Replace with the path to your chromedriver executable\n",
    ")\n",
    "service = Service()\n",
    "\n",
    "# Set up Chrome driver\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Navigate to the URL\n",
    "url = \"https://www.escolha.ufop.br/cursos\"\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# Find elements with class \"ufop-glossary-row\"\n",
    "elements = driver.find_elements(By.CLASS_NAME, \"ufop-glossary-row\")\n",
    "\n",
    "# Extract the href links from child anchor 'a' tags\n",
    "links = []\n",
    "courses_dict = {\"id\": [], \"code\": [], \"name\": []}\n",
    "for element in elements:\n",
    "    link_element = element.find_element(By.TAG_NAME, \"a\")\n",
    "    href = link_element.get_attribute(\"href\")\n",
    "    links.append(href)\n",
    "\n",
    "    courses_dict[\"id\"].append(str(uuid.uuid4()))\n",
    "    courses_dict[\"code\"].append(format_course_name(link_element.text))\n",
    "    courses_dict[\"name\"].append(link_element.text)\n",
    "\n",
    "\n",
    "\n",
    "indexes_to_delete = []\n",
    "course_pdfs = []\n",
    "\n",
    "# Navigate to each link and download PDF files\n",
    "print(\"Buscando os links .pdf ...\")\n",
    "with tqdm(total=len(links), desc=\"Progresso\", ascii=True) as pbar:\n",
    "    for i, link in enumerate(links):\n",
    "        driver.get(link)\n",
    "\n",
    "        matriz_elements = driver.find_elements(\n",
    "            By.CLASS_NAME, \"field-name-field-matriz-curricular\"\n",
    "        )\n",
    "\n",
    "        for element in matriz_elements:\n",
    "            link_elements = element.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "            if len(link_elements) == 1:\n",
    "                href = link_elements[0].get_attribute(\"href\")\n",
    "                course_pdfs.append({\"course\": courses_dict[\"code\"][i], \"link\": href})\n",
    "                continue\n",
    "\n",
    "            for link_element in link_elements:\n",
    "                href = link_element.get_attribute(\"href\")\n",
    "                course_type = link_element.text\n",
    "                course_name = f\"{courses_dict['name'][i]} ({course_type})\"\n",
    "                course_code = format_course_name(course_name)\n",
    "                courses_dict[\"id\"].append(str(uuid.uuid4()))\n",
    "                courses_dict[\"name\"].append(course_name)\n",
    "                courses_dict[\"code\"].append(course_code)\n",
    "\n",
    "                course_pdfs.append({\"course\": course_code, \"link\": href})\n",
    "            indexes_to_delete.append(i)\n",
    "\n",
    "        pbar.set_postfix(curso=f\"{courses_dict['name'][i]}\")\n",
    "        pbar.update(1)\n",
    "\n",
    "courses_dict[\"id\"] = [\n",
    "    item for i, item in enumerate(courses_dict[\"id\"]) if i not in indexes_to_delete\n",
    "]\n",
    "courses_dict[\"code\"] = [\n",
    "    item for i, item in enumerate(courses_dict[\"name\"]) if i not in indexes_to_delete\n",
    "]\n",
    "courses_dict[\"name\"] = [\n",
    "    item for i, item in enumerate(courses_dict[\"name\"]) if i not in indexes_to_delete\n",
    "]\n",
    "\n",
    "valid_pdf_substrings = [\".pdf\", \"codCurso=\"]\n",
    "for pdf in course_pdfs:\n",
    "    import os\n",
    "\n",
    "for pdf in course_pdfs:\n",
    "    if any(text in pdf[\"link\"] for text in valid_pdf_substrings):\n",
    "        response = requests.get(pdf[\"link\"])\n",
    "        parsed_url = urlparse(pdf[\"link\"])\n",
    "        filename = f\"{pdf['course']}.pdf\"\n",
    "        file_path = os.path.join(pdfs_folder_path, filename)\n",
    "\n",
    "        # Check if the file already exists in the folder\n",
    "        if not os.path.exists(file_path):\n",
    "            with open(file_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"{filename} salvo com sucesso.\")\n",
    "        else:\n",
    "            print(f\"{filename} já existe no diretório. Pulando...\")\n",
    "\n",
    "\n",
    "# Quit the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "courses_df = pd.DataFrame(courses_dict).sort_values(by='code', ascending = True)\n",
    "courses_df['created_at'] = datetime.now()\n",
    "courses_df.to_csv(f\"{tables_folder_path}/course.csv\", index=False)\n",
    "\n",
    "courses_df = courses_df[(~courses_df.isin(existing_data['course'])).all(1)]\n",
    "\n",
    "# Save courses table in database\n",
    "courses_df.to_sql('course', engine, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando DECEA\n",
      "Buscando DECSI\n",
      "Buscando DEELT\n",
      "Buscando DEENP\n",
      "Buscando DEETE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "518"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "URL = \"https://zeppelin10.ufop.br/HorarioAulas/\"\n",
    "\n",
    "desired_departments = [\"DECSI\", \"DECEA\", \"DEELT\", \"DEENP\", \"DEETE\"]\n",
    "semester = \"23.1\"\n",
    "\n",
    "\n",
    "def get_HTML_content(URL, department):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(URL)\n",
    "    elem = driver.find_element(By.XPATH, \"//*[text()='{}']\".format(department))\n",
    "    elem.click()\n",
    "    URL = driver.current_url\n",
    "    html_source = driver.page_source\n",
    "    soup = BeautifulSoup(html_source, \"lxml\")\n",
    "    driver.quit()\n",
    "    return soup\n",
    "\n",
    "\n",
    "def parse_schedule_string(schedule_string):\n",
    "    entries = []\n",
    "    \n",
    "    if schedule_string == '':\n",
    "        return entries\n",
    "    \n",
    "    schedule_parts = schedule_string.split(\" / \")\n",
    "    \n",
    "    if len(schedule_parts) == 0:\n",
    "        schedule_parts.append(schedule_string)\n",
    "\n",
    "    for part in schedule_parts:\n",
    "        day, time_info = part.split(\" \")\n",
    "        start_time, end_time = time_info.split(\"-\")\n",
    "        class_type = end_time[-2]  # T for theoretical, P for practical\n",
    "        end_time = end_time[:-3]  # Remove the class type from end_time\n",
    "\n",
    "        entry = {\n",
    "            \"day_of_week\": day,\n",
    "            \"start_time\":  datetime.strptime(start_time, \"%H:%M\").time(),\n",
    "            \"end_time\": datetime.strptime(end_time, \"%H:%M\").time(),\n",
    "            \"class_type\": class_type,\n",
    "        }\n",
    "        entries.append(entry)\n",
    "\n",
    "    return entries\n",
    "\n",
    "\n",
    "def get_field_list(html_content, field):\n",
    "    field_list = []\n",
    "    table = html_content.find(\"table\", {\"id\": \"formPrincipal:tabela\"})\n",
    "    if table:\n",
    "        tbody = table.find(\"tbody\")\n",
    "        tr_elements = tbody.find_all(\"tr\")\n",
    "\n",
    "        for i, tr in enumerate(tr_elements):\n",
    "            if field == \"descricao\":\n",
    "                span = tr.find(\n",
    "                    \"span\", {\"id\": \"formPrincipal:tabela:{}:{}\".format(i, \"disciplina\")}\n",
    "                )\n",
    "                title = span.find_parent(\"a\").get(\n",
    "                    \"title\"\n",
    "                )  # Extract the 'title' attribute of the parent <a> tag\n",
    "                field_list.append(title)\n",
    "                continue\n",
    "\n",
    "            span = tr.find(\n",
    "                \"span\", {\"id\": \"formPrincipal:tabela:{}:{}\".format(i, field)}\n",
    "            )\n",
    "            field_list.append(span.text)\n",
    "\n",
    "    return field_list\n",
    "\n",
    "\n",
    "def get_departments():\n",
    "    r = requests.get(URL)\n",
    "    departments_list = []\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")  # Use 'html.parser' as the parser\n",
    "\n",
    "    # Find the table with the specified id\n",
    "    table = soup.find(\"table\", {\"id\": \"formPrincipal:tabela\"})\n",
    "    if table:\n",
    "        tbody = table.find(\"tbody\")\n",
    "\n",
    "        # Find all <tr> elements within <tbody>\n",
    "        tr_elements = tbody.find_all(\"tr\")\n",
    "\n",
    "        for i, tr in enumerate(tr_elements):\n",
    "            tableCode = tr.find(\n",
    "                \"span\", {\"id\": \"formPrincipal:tabela:{}:codigoDepartamento\".format(i)}\n",
    "            )\n",
    "            tableName = tr.find(\n",
    "                \"span\", {\"id\": \"formPrincipal:tabela:{}:descricao\".format(i)}\n",
    "            )\n",
    "\n",
    "            \n",
    "            departments_list.append(\n",
    "                {\"id\": uuid.uuid4(), \"code\": tableCode.text.strip(), \"name\": tableName.text.strip()}\n",
    "            )\n",
    "            \n",
    "\n",
    "        departments_df = pd.DataFrame(departments_list)\n",
    "        departments_df[\"created_at\"] = datetime.now()\n",
    "        return departments_df, departments_list\n",
    "\n",
    "\n",
    "def get_discipline_tables(departments_list):\n",
    "    discipline_dict = {\"id\": [], \"code\": [], \"name\": [], \"description\": [], \"department_id\": []}\n",
    "    class_dict = {\n",
    "        \"id\": [],\n",
    "        \"class_number\": [],\n",
    "        \"discipline_id\": [],\n",
    "        \"professor\": [],\n",
    "    }\n",
    "    schedule_dict = {\n",
    "        \"id\": [],\n",
    "        \"discipline_class_id\": [],\n",
    "        \"day_of_week\": [],\n",
    "        \"start_time\": [],\n",
    "        \"end_time\": [],\n",
    "        \"class_type\": [],\n",
    "    }\n",
    "\n",
    "    for department in departments_list:\n",
    "        if department['code'] not in desired_departments:\n",
    "            continue\n",
    "\n",
    "        print(f\"Buscando {department['code']}\")\n",
    "        html_content = get_HTML_content(URL, department['code'])\n",
    "        columns_list = [\n",
    "            \"codigo\",\n",
    "            \"disciplina\",\n",
    "            \"descricao\",\n",
    "            \"turma\",\n",
    "            \"horario\",\n",
    "            \"professores\",\n",
    "        ]\n",
    "        columns_dict_list = {}\n",
    "\n",
    "        for column_name in columns_list:\n",
    "            field = get_field_list(html_content, column_name)\n",
    "            columns_dict_list[column_name] = field\n",
    "\n",
    "        for i in range(len(columns_dict_list[\"codigo\"])):\n",
    "            discipline_id = str(uuid.uuid4())\n",
    "            discipline_dict[\"id\"].append(discipline_id)\n",
    "            discipline_dict[\"code\"].append(columns_dict_list[\"codigo\"][i])\n",
    "            discipline_dict[\"name\"].append(columns_dict_list[\"disciplina\"][i])\n",
    "            discipline_dict[\"description\"].append(columns_dict_list[\"descricao\"][i])\n",
    "            discipline_dict[\"department_id\"].append(department['id'])\n",
    "\n",
    "            discipline_class_id = str(uuid.uuid4())\n",
    "            class_dict[\"id\"].append(discipline_class_id)\n",
    "            class_dict[\"class_number\"].append(columns_dict_list[\"turma\"][i])\n",
    "            class_dict[\"discipline_id\"].append(discipline_id)\n",
    "            class_dict[\"professor\"].append(columns_dict_list[\"professores\"][i])\n",
    "\n",
    "            schedule_entries = parse_schedule_string(columns_dict_list[\"horario\"][i])\n",
    "            for entry in schedule_entries:\n",
    "                schedule_dict[\"id\"].append(str(uuid.uuid4()))\n",
    "                schedule_dict[\"discipline_class_id\"].append(discipline_class_id)\n",
    "                schedule_dict[\"day_of_week\"].append(entry[\"day_of_week\"])\n",
    "                schedule_dict[\"start_time\"].append(entry[\"start_time\"])\n",
    "                schedule_dict[\"end_time\"].append(entry[\"end_time\"])\n",
    "                schedule_dict[\"class_type\"].append(entry[\"class_type\"])\n",
    "\n",
    "    discipline_df = pd.DataFrame(discipline_dict).drop_duplicates()\n",
    "    class_df = pd.DataFrame(class_dict)\n",
    "    schedule_df = pd.DataFrame(schedule_dict)\n",
    "\n",
    "    currentTime = datetime.now()\n",
    "\n",
    "    discipline_df[\"created_at\"] = currentTime\n",
    "    class_df[\"created_at\"] = currentTime\n",
    "    class_df[\"semester\"] = semester\n",
    "    schedule_df[\"created_at\"] = currentTime\n",
    "\n",
    "    return discipline_df, class_df, schedule_df\n",
    "\n",
    "\n",
    "department_df, departments_list = get_departments()\n",
    "department_df.to_csv(f\"{tables_folder_path}/department.csv\", index=False)\n",
    "department_df = department_df[(~department_df.isin(existing_data['department'])).all(1)]\n",
    "department_df.to_sql(\"department\", engine, index=False, if_exists=\"append\")\n",
    "\n",
    "(\n",
    "    discipline_df,\n",
    "    discipline_class_df,\n",
    "    discipline_class_schedule_df,\n",
    ") = get_discipline_tables(departments_list)\n",
    "discipline_df.to_csv(f\"{tables_folder_path}/discipline.csv\", index=False)\n",
    "discipline_df = discipline_df[(~discipline_df.isin(existing_data['discipline'])).all(1)]\n",
    "discipline_df.to_sql(\"discipline\", engine, index=False, if_exists=\"append\")\n",
    "\n",
    "discipline_class_df.to_csv(f\"{tables_folder_path}/discipline_class.csv\", index=False)\n",
    "discipline_class_df = discipline_class_df[(~discipline_class_df.isin(existing_data['discipline_class'])).all(1)]\n",
    "discipline_class_df.to_sql(\"discipline_class\", engine, index=False, if_exists=\"append\")\n",
    "\n",
    "discipline_class_schedule_df.to_csv(\n",
    "    f\"{tables_folder_path}/discipline_class_schedule.csv\", index=False\n",
    ")\n",
    "discipline_class_schedule_df = discipline_class_schedule_df[(~discipline_class_schedule_df.isin(existing_data['discipline_class_schedule'])).all(1)]\n",
    "discipline_class_schedule_df.to_sql(\n",
    "    \"discipline_class_schedule\", engine, index=False, if_exists=\"append\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando ./courses_pdfs/engenharia-de-computacao.pdf\n",
      "Buscando ./courses_pdfs/engenharia-de-producao-jm.pdf\n",
      "Buscando ./courses_pdfs/sistemas-de-informacao.pdf\n",
      "Buscando ./courses_pdfs/engenharia-eletrica.pdf\n"
     ]
    }
   ],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "import re\n",
    "\n",
    "code_pattern = r\"[A-Z]{3}\\d{3}\"\n",
    "subject_pattern = r\"\\b[A-Z]+\\b\"\n",
    "classes_pattern = r\"^(T P|T|P)$\"\n",
    "prerequisite_pattern = r\"[A-Z]{3}\\d{3}|\\d+\\s+horas\"\n",
    "chs_che_pattern = r\"^\\d+\\/\\d+$\"\n",
    "\n",
    "\n",
    "def get_col_idx(df_value, pattern):\n",
    "    indexes = []\n",
    "    for i, item in enumerate(df_value):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        match = re.search(pattern, str(item), re.UNICODE)\n",
    "        if match is not None:\n",
    "            indexes.append(i)\n",
    "\n",
    "    return indexes\n",
    "\n",
    "\n",
    "def replace_carriage_return(arr):\n",
    "    series = pd.Series(arr)\n",
    "\n",
    "    # Replace '\\r' with an empty string in the Series values\n",
    "    series = series.astype(str).str.replace(r\"\\r\", \"\")\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "def get_prerequisites(df_value):\n",
    "    prerequisites = []\n",
    "    prereq_idx = get_col_idx(df_value, prerequisite_pattern)\n",
    "    if len(prereq_idx) > 0:\n",
    "        prerequisites = [df_value[i] for i in prereq_idx]\n",
    "\n",
    "    return format_prerequisites(prerequisites)\n",
    "\n",
    "\n",
    "def get_discipline(df_value):\n",
    "    subject_idx = get_col_idx(df_value, subject_pattern)\n",
    "    if len(subject_idx) > 0:\n",
    "        return re.sub(code_pattern, \"\", df_value[subject_idx[0]])\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_chs_che(df_value):\n",
    "    chs_che_idx = get_col_idx(df_value, chs_che_pattern)\n",
    "\n",
    "    if len(chs_che_idx) > 0:\n",
    "        chs_che_list = df_value[chs_che_idx[0]].split(\"/\")\n",
    "        return tuple(map(int, chs_che_list))\n",
    "\n",
    "    return (\"\", \"\")\n",
    "\n",
    "\n",
    "def get_classes(df_value, classes_idx):\n",
    "    classes = []\n",
    "    if len(classes_idx) > 0:\n",
    "        classes = [df_value[i] for i in classes_idx]\n",
    "        return \" \".join(classes)\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_period(df_value, eletiva):\n",
    "    if eletiva or not df_value[0]:\n",
    "        return \"\"\n",
    "\n",
    "    for item in reversed(df_value):\n",
    "        if item:\n",
    "            return int(item)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_period2(df_value, mandatory):\n",
    "    if not mandatory or not df_value[0]:\n",
    "        return \"\"\n",
    "\n",
    "    for item in reversed(df_value):\n",
    "        if item:\n",
    "            return int(item)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_cha(df_value, chs):\n",
    "    if not chs:\n",
    "        return \"\"\n",
    "\n",
    "    chs_alt = chs * 1.2\n",
    "\n",
    "    if len(df_value) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    for text in df_value:\n",
    "        try:\n",
    "            formatted_text = int(text)\n",
    "            if formatted_text == chs or formatted_text == chs_alt:\n",
    "                return formatted_text\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def format_prerequisites(df_value):\n",
    "    if len(df_value) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    requisites = []\n",
    "    for text in df_value:\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        matches = re.findall(code_pattern, text)\n",
    "        requisites.extend(matches)\n",
    "\n",
    "    joined_matches = \" \".join(requisites)\n",
    "    return joined_matches\n",
    "\n",
    "\n",
    "def get_formatted_df(df, eletiva):\n",
    "    df = df.replace({r\"\\r\": \" \"}, regex=True)\n",
    "    df_struct = {\n",
    "        \"codigo\": [],\n",
    "        \"disciplina\": [],\n",
    "        \"prerequisitos\": [],\n",
    "        \"chs\": [],\n",
    "        \"che\": [],\n",
    "        \"cha\": [],\n",
    "        \"aulas\": [],\n",
    "        \"periodo\": [],\n",
    "    }\n",
    "    ideal_df = pd.DataFrame(data=df_struct)\n",
    "\n",
    "    ideal_columns = ideal_df.columns.to_list()\n",
    "\n",
    "    column_names = df.columns.tolist()\n",
    "    disc_indexes = [i for i, item in enumerate(column_names) if \"DISCIPLINAS\" in item]\n",
    "\n",
    "    iterIdx = -1\n",
    "    classes_idx = []\n",
    "\n",
    "    for idx, value in enumerate(df.values):\n",
    "        if idx == 0:\n",
    "            iterIdx = -1\n",
    "            classes_idx = get_col_idx(value, classes_pattern)\n",
    "            ideal_df.at[0, ideal_columns[0]] = \"\"\n",
    "            ideal_df.at[0, ideal_columns[1]] = \"\"\n",
    "            ideal_df.at[0, ideal_columns[2]] = \"\"\n",
    "            ideal_df.at[0, ideal_columns[3]] = \"\"\n",
    "            ideal_df.at[0, ideal_columns[4]] = \"\"\n",
    "            ideal_df.at[0, ideal_columns[5]] = \"\"\n",
    "            ideal_df.at[0, ideal_columns[6]] = \"\"\n",
    "            ideal_df.at[0, ideal_columns[7]] = \"\"\n",
    "            continue\n",
    "\n",
    "        chs, che = get_chs_che(value)\n",
    "        ideal_df.at[idx, ideal_columns[0]] = value[0]\n",
    "        ideal_df.at[idx, ideal_columns[1]] = get_discipline(value)\n",
    "        ideal_df.at[idx, ideal_columns[2]] = get_prerequisites(value)\n",
    "        ideal_df.at[idx, ideal_columns[3]] = chs\n",
    "        ideal_df.at[idx, ideal_columns[4]] = che\n",
    "        ideal_df.at[idx, ideal_columns[5]] = get_cha(value, chs)\n",
    "        ideal_df.at[idx, ideal_columns[6]] = get_classes(value, classes_idx)\n",
    "        ideal_df.at[idx, ideal_columns[7]] = get_period(value, eletiva)\n",
    "\n",
    "        if value[0] != \"\":\n",
    "            iterIdx = -1\n",
    "            continue\n",
    "\n",
    "        if iterIdx == -1:\n",
    "            iterIdx = idx - 1\n",
    "\n",
    "        ideal_df.loc[iterIdx, :] = [\n",
    "            f\"{item1} {item2}\".strip()\n",
    "            for item1, item2 in zip(ideal_df.values[iterIdx], ideal_df.values[idx])\n",
    "        ]\n",
    "\n",
    "    ideal_df.drop(ideal_df[ideal_df[\"codigo\"] == \"\"].index, inplace=True)\n",
    "    ideal_df[[\"chs\", \"che\", \"cha\"]] = ideal_df[[\"chs\", \"che\", \"cha\"]].astype(int)\n",
    "    ideal_df[\"eletiva\"] = eletiva\n",
    "\n",
    "    return ideal_df\n",
    "\n",
    "\n",
    "def get_prerequisite_df(discipline_course_df):\n",
    "    prerequisite_df = pd.concat(\n",
    "        discipline_course_df.apply(create_prerequisite_rows, axis=1).tolist(),\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    prerequisite_df[\"created_at\"] = datetime.now()\n",
    "    return prerequisite_df\n",
    "\n",
    "\n",
    "def create_prerequisite_rows(row):\n",
    "    prerequisites = row[\"prerequisites\"].split()\n",
    "    if len(prerequisites):\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                \"id\": [str(uuid.uuid4()) for _ in range(len(prerequisites))],\n",
    "                \"discipline_course_id\": [row[\"id\"] for _ in range(len(prerequisites))],\n",
    "                \"prerequisite_discipline_id\": prerequisites,\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def get_discipline_course_tables(df, course_id, mandatory):\n",
    "    df = df.replace({r\"\\r\": \" \"}, regex=True)\n",
    "    df_struct = {\"id\": [], \"discipline_id\": [], \"period\": [], \"prerequisites\": []}\n",
    "    discipline_course_df = pd.DataFrame(data=df_struct)\n",
    "\n",
    "    ideal_columns = discipline_course_df.columns.to_list()\n",
    "\n",
    "    column_names = df.columns.tolist()\n",
    "    disc_indexes = [i for i, item in enumerate(column_names) if \"DISCIPLINAS\" in item]\n",
    "\n",
    "    iterIdx = -1\n",
    "\n",
    "    for idx, value in enumerate(df.values):\n",
    "        if idx == 0:\n",
    "            iterIdx = -1\n",
    "            discipline_course_df.at[0, \"id\"] = \"\"\n",
    "            discipline_course_df.at[0, \"discipline_id\"] = \"\"\n",
    "            discipline_course_df.at[0, \"period\"] = \"\"\n",
    "            discipline_course_df.at[0, \"prerequisites\"] = \"\"\n",
    "            continue\n",
    "\n",
    "        discipline_course_df.at[idx, \"id\"] = str(uuid.uuid4())\n",
    "        discipline_course_df.at[idx, \"discipline_id\"] = value[0]\n",
    "        discipline_course_df.at[idx, \"period\"] = get_period2(value, mandatory)\n",
    "        discipline_course_df.at[idx, \"prerequisites\"] = get_prerequisites(value)\n",
    "\n",
    "        if value[0] != \"\":\n",
    "            iterIdx = -1\n",
    "            continue\n",
    "\n",
    "        if iterIdx == -1:\n",
    "            iterIdx = idx - 1\n",
    "\n",
    "        discipline_course_df.loc[iterIdx, :] = [\n",
    "            f\"{item1} {item2}\".strip()\n",
    "            for item1, item2 in zip(\n",
    "                discipline_course_df.values[iterIdx], discipline_course_df.values[idx]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    discipline_course_df.drop(\n",
    "        discipline_course_df[discipline_course_df[\"discipline_id\"] == \"\"].index,\n",
    "        inplace=True,\n",
    "    )\n",
    "    discipline_course_df[\"mandatory\"] = mandatory\n",
    "    discipline_course_df[\"course_id\"] = course_id\n",
    "    prerequisite_df = pd.DataFrame()\n",
    "    if not discipline_course_df.empty:\n",
    "        prerequisite_df = get_prerequisite_df(discipline_course_df)\n",
    "\n",
    "    discipline_course_df.drop(\"prerequisites\", axis=1)\n",
    "\n",
    "    return discipline_course_df, prerequisite_df\n",
    "\n",
    "\n",
    "def save_table_to_csv(df):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    filename = \"table.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Table saved as {filename}\")\n",
    "\n",
    "\n",
    "def save_table_to_json(df):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    filename = \"table.json\"\n",
    "    df.to_json(filename, orient=\"records\")\n",
    "    print(f\"Table saved as {filename}\")\n",
    "\n",
    "\n",
    "def scrape_table_from_pdf(pdf_path):\n",
    "    # Read the table from the PDF file\n",
    "    df_list = tabula.read_pdf(pdf_path, pages=\"all\")\n",
    "\n",
    "    course_id = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "\n",
    "    discipline_course_dfs = []\n",
    "    prerequisite_dfs = []\n",
    "\n",
    "    for df in df_list:\n",
    "        df.fillna(\"\", inplace=True)\n",
    "        # Filter and select the desired columns based on the header\n",
    "        header = df.columns.to_list()\n",
    "        eletivas_column = next(\n",
    "            (col for col in header if \"DISCIPLINAS ELETIVAS\" in col), None\n",
    "        )\n",
    "        obrigatorias_column = next(\n",
    "            (col for col in header if \"DISCIPLINAS OBRIGATÓRIAS\" in col), None\n",
    "        )\n",
    "\n",
    "        if \"DISCIPLINAS OBRIGATÓRIAS\" in header:\n",
    "            discipline_course_df, prerequiste_df = get_discipline_course_tables(\n",
    "                df, course_id, True\n",
    "            )\n",
    "            discipline_course_dfs.append(discipline_course_df)\n",
    "            prerequisite_dfs.append(prerequiste_df)\n",
    "\n",
    "        elif (\n",
    "            \"DISCIPLINAS ELETIVAS\" in header\n",
    "            or \"DISCIPLINAS ELETIVAS PRÉ-REQUISITO\" in header\n",
    "        ):\n",
    "            discipline_course_df, prerequiste_df = get_discipline_course_tables(\n",
    "                df, course_id, False\n",
    "            )\n",
    "            discipline_course_dfs.append(discipline_course_df)\n",
    "            prerequisite_dfs.append(prerequiste_df)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    combined_discipline_course_df = pd.concat(discipline_course_dfs, ignore_index=True)\n",
    "\n",
    "    combined_prerequisite_df = pd.concat(prerequisite_dfs, ignore_index=True)\n",
    "    discipline_course_df = combined_discipline_course_df[\n",
    "        combined_discipline_course_df[\"discipline_id\"].isin(discipline_df[\"id\"])\n",
    "    ]\n",
    "\n",
    "    prerequisite_df = combined_prerequisite_df\n",
    "    if not combined_prerequisite_df.empty:\n",
    "        prerequisite_df = combined_prerequisite_df[\n",
    "            combined_prerequisite_df[\"discipline_course_id\"].isin(\n",
    "                discipline_course_df[\"id\"]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    return discipline_course_df, prerequisite_df\n",
    "\n",
    "\n",
    "files = os.listdir(pdfs_folder_path)\n",
    "pdf_files = [\n",
    "    os.path.join(pdfs_folder_path, file) for file in files if file.endswith(\".pdf\")\n",
    "]\n",
    "\n",
    "for pdf_file in [\n",
    "    \"./courses_pdfs/engenharia-de-computacao.pdf\",\n",
    "    \"./courses_pdfs/engenharia-de-producao-jm.pdf\",\n",
    "    \"./courses_pdfs/sistemas-de-informacao.pdf\",\n",
    "    \"./courses_pdfs/engenharia-eletrica.pdf\",\n",
    "]:\n",
    "    print(f\"Buscando {pdf_file}\")\n",
    "    discipline_course_df, prerequisite_df = scrape_table_from_pdf(pdf_file)\n",
    "    discipline_course_df.to_csv(\n",
    "        f\"{tables_folder_path}/discipline_course.csv\",\n",
    "        mode=\"a\",\n",
    "        header=not os.path.exists(f\"{tables_folder_path}/discipline_course.csv\"),\n",
    "        index=False,\n",
    "    )\n",
    "    discipline_course_df = discipline_course_df[(~discipline_course_df.isin(existing_data['discipline_course'])).all(1)]\n",
    "    discipline_course_df.to_sql(\n",
    "        \"discipline_course\", con=engine, if_exists=\"append\", index=False\n",
    "    )\n",
    "\n",
    "    prerequisite_df.to_csv(\n",
    "        f\"{tables_folder_path}/prerequisite.csv\",\n",
    "        mode=\"a\",\n",
    "        header=not os.path.exists(f\"{tables_folder_path}/prerequisite.csv\"),\n",
    "        index=False,\n",
    "    )\n",
    "    prerequisite_df = prerequisite_df[(~prerequisite_df.isin(existing_data['prerequisite'])).all(1)]\n",
    "    prerequisite_df.to_sql(\"prerequisite\", con=engine, if_exists=\"append\", index=False)\n",
    "\n",
    "# discipline_course_df, prerequisite_df = scrape_table_from_pdf(\n",
    "#     \"./courses_pdfs/fisica-bacharelado.pdf\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(pdfs_folder_path)\n",
    "pdf_files = [\n",
    "    os.path.join(pdfs_folder_path, file) for file in files if file.endswith(\".pdf\")\n",
    "]\n",
    "print(len(pdf_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
