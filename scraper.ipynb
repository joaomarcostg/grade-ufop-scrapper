{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install selenium bs4 tqdm sqlalchemy tabula-py psycopg2-binary lxml python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup \n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import re\n",
    "from collections import defaultdict  # Add this line\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create the \"tables\" folder if it doesn't exist\n",
    "tables_folder_path = \"./tables\"\n",
    "if not os.path.exists(tables_folder_path):\n",
    "    os.makedirs(tables_folder_path)\n",
    "\n",
    "\n",
    "# Create the \"matrizes\" folder if it doesn't exist\n",
    "pdfs_folder_path = \"./courses_pdfs\"\n",
    "if not os.path.exists(pdfs_folder_path):\n",
    "    os.makedirs(pdfs_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, inspect\n",
    "from sqlalchemy.sql import text\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "def wipe_database_tables():\n",
    "    load_dotenv()\n",
    "\n",
    "    # Create a connection to the PostgreSQL database\n",
    "    conn_str = os.getenv('DB_URL')\n",
    "    engine = create_engine(conn_str)\n",
    "\n",
    "    # Create inspector\n",
    "    inspector = inspect(engine)\n",
    "\n",
    "    # Get table names, excluding unwanted tables\n",
    "    unwanted = {'session', 'account', 'user', 'verification_token'}\n",
    "    table_names = [e for e in inspector.get_table_names() if e not in unwanted]\n",
    "\n",
    "    # Confirm with the user\n",
    "    print(f\"This will delete all data from the following tables:\")\n",
    "    print(\", \".join(table_names))\n",
    "    confirmation = input(\"Are you sure you want to proceed? (yes/no): \")\n",
    "\n",
    "    if confirmation.lower() != 'yes':\n",
    "        print(\"Operation cancelled.\")\n",
    "        return\n",
    "\n",
    "    # Truncate tables\n",
    "    with engine.connect() as connection:\n",
    "        # Start a transaction\n",
    "        with connection.begin():\n",
    "            for table in table_names:\n",
    "                # Use TRUNCATE with CASCADE to handle foreign key constraints\n",
    "                connection.execute(text(f\"TRUNCATE TABLE {table} CASCADE;\"))\n",
    "        \n",
    "        print(\"All specified tables have been wiped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, inspect\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Create a connection to the PostgreSQL database\n",
    "conn_str = os.getenv('DB_URL')\n",
    "print(conn_str)\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# create inspector\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# get table names\n",
    "unwanted = {'session', 'account', 'user', 'verification_token'}\n",
    "table_names = [e for e in inspector.get_table_names() if e not in unwanted]\n",
    "print(table_names)\n",
    "\n",
    "# initialize an empty dictionary to hold the data\n",
    "existing_data = {}\n",
    "\n",
    "# iterate over all table names\n",
    "for table in table_names:\n",
    "    # read the data from the table and save it to the dictionary\n",
    "    existing_data[table] = pd.read_sql(f'SELECT * FROM {table}', engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def store_df(df, table):\n",
    "    # Store the DataFrame in database\n",
    "    df.to_sql(table, engine, index=False, if_exists='append')\n",
    "    \n",
    "    # Append the DataFrame to its CSV file\n",
    "    df.to_csv(\n",
    "        f\"{tables_folder_path}/{table}.csv\",\n",
    "        mode=\"a\",\n",
    "        header=not os.path.exists(f\"{tables_folder_path}/{table}.csv\"),\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def format_course_name(text):\n",
    "    # Remove accent marks\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "    \n",
    "    # Replace symbols with a hyphen\n",
    "    text = re.sub(r'[^a-zA-Z0-9]+', '-', text)\n",
    "    \n",
    "    # Remove leading and trailing hyphens\n",
    "    text = text.strip('-')\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def get_discipline_prefix(code):\n",
    "    match = re.match(r\"([A-Z]{3})\\d{3}\", code)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def handle_equivalencies(disciplines_data):\n",
    "    equivalency_groups = defaultdict(list)\n",
    "    \n",
    "    for discipline in disciplines_data:\n",
    "        key = (discipline['name'], get_discipline_prefix(discipline['code']))\n",
    "        equivalency_groups[key].append(discipline)\n",
    "    \n",
    "    return [group for group in equivalency_groups.values() if len(group) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busca cursos e salva os .pdfs na pasta /matrizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# # Set up Chrome options\n",
    "# chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "# chrome_options.add_argument(\"--disable-gpu\")\n",
    "# chrome_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "# # Set up Chrome driver service\n",
    "# chromedriver_path = (\n",
    "#     \"./chromedriver\"  # Replace with the path to your chromedriver executable\n",
    "# )\n",
    "# service = Service()\n",
    "\n",
    "# # Set up Chrome driver\n",
    "# driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# # Navigate to the URL\n",
    "# url = \"https://www.escolha.ufop.br/cursos\"\n",
    "# driver.get(url)\n",
    "\n",
    "\n",
    "# # Find elements with class \"ufop-glossary-row\"\n",
    "# elements = driver.find_elements(By.CLASS_NAME, \"ufop-glossary-row\")\n",
    "\n",
    "# # Extract the href links from child anchor 'a' tags\n",
    "# links = []\n",
    "# courses_dict = {\"id\": [], \"code\": [], \"name\": []}\n",
    "\n",
    "# print(\"Buscando a lista de cursos da UFOP...\")\n",
    "# with tqdm(total=len(elements), desc=\"Progresso\", ascii=True) as pbar:\n",
    "#     for element in elements:\n",
    "#         link_element = element.find_element(By.TAG_NAME, \"a\")\n",
    "#         href = link_element.get_attribute(\"href\")\n",
    "#         links.append(href)\n",
    "\n",
    "#         courses_dict[\"id\"].append(str(uuid.uuid4()))\n",
    "#         courses_dict[\"code\"].append(format_course_name(link_element.text))\n",
    "#         courses_dict[\"name\"].append(link_element.text)\n",
    "#         pbar.set_postfix(curso=f\"{link_element.text}\")\n",
    "#         pbar.update(1)\n",
    "\n",
    "# indexes_to_delete = []\n",
    "# course_pdfs = []\n",
    "\n",
    "# # Navigate to each link and download PDF files\n",
    "# print(\"\\nBuscando os links .pdf ...\")\n",
    "# with tqdm(total=len(links), desc=\"Progresso\", ascii=True) as pbar:\n",
    "#     for i, link in enumerate(links):\n",
    "#         driver.get(link)\n",
    "\n",
    "#         matriz_elements = driver.find_elements(\n",
    "#             By.CLASS_NAME, \"field-name-field-matriz-curricular\"\n",
    "#         )\n",
    "\n",
    "#         for element in matriz_elements:\n",
    "#             link_elements = element.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "#             if len(link_elements) == 1:\n",
    "#                 href = link_elements[0].get_attribute(\"href\")\n",
    "#                 course_pdfs.append({\"course\": courses_dict[\"code\"][i], \"link\": href})\n",
    "#                 continue\n",
    "\n",
    "#             for link_element in link_elements:\n",
    "#                 href = link_element.get_attribute(\"href\")\n",
    "#                 course_type = link_element.text\n",
    "#                 course_name = f\"{courses_dict['name'][i]} ({course_type})\"\n",
    "#                 course_code = format_course_name(course_name)\n",
    "#                 courses_dict[\"id\"].append(str(uuid.uuid4()))\n",
    "#                 courses_dict[\"name\"].append(course_name)\n",
    "#                 courses_dict[\"code\"].append(course_code)\n",
    "\n",
    "#                 course_pdfs.append({\"course\": course_code, \"link\": href})\n",
    "#             indexes_to_delete.append(i)\n",
    "\n",
    "#         pbar.set_postfix(curso=f\"{courses_dict['name'][i]}\")\n",
    "#         pbar.update(1)\n",
    "\n",
    "# courses_dict[\"id\"] = [\n",
    "#     item for i, item in enumerate(courses_dict[\"id\"]) if i not in indexes_to_delete\n",
    "# ]\n",
    "# courses_dict[\"code\"] = [\n",
    "#     item for i, item in enumerate(courses_dict[\"code\"]) if i not in indexes_to_delete\n",
    "# ]\n",
    "# courses_dict[\"name\"] = [\n",
    "#     item for i, item in enumerate(courses_dict[\"name\"]) if i not in indexes_to_delete\n",
    "# ]\n",
    "\n",
    "# valid_pdf_substrings = [\".pdf\", \"codCurso=\"]\n",
    "# for pdf in course_pdfs:\n",
    "#     import os\n",
    "\n",
    "# print(\"\\nSalvando os arquivos .pdf dos cursos\")\n",
    "# with tqdm(total=len(course_pdfs), desc=\"Progresso\", ascii=True) as pbar:\n",
    "\n",
    "#     for pdf in course_pdfs:\n",
    "#         if any(text in pdf[\"link\"] for text in valid_pdf_substrings):\n",
    "#             response = requests.get(pdf[\"link\"])\n",
    "#             parsed_url = urlparse(pdf[\"link\"])\n",
    "#             filename = f\"{pdf['course']}.pdf\"\n",
    "#             file_path = os.path.join(pdfs_folder_path, filename)\n",
    "\n",
    "#             # Check if the file already exists in the folder\n",
    "#             if not os.path.exists(file_path):\n",
    "#                 with open(file_path, \"wb\") as file:\n",
    "#                     file.write(response.content)\n",
    "        \n",
    "#         pbar.set_postfix(salvando=f\"{pdf['course']}.pdf\")\n",
    "#         pbar.update(1)\n",
    "        \n",
    "# # Quit the driver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salva os cursos encontrados no banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# course_df = pd.DataFrame(courses_dict).sort_values(by=\"code\", ascending=True)\n",
    "# course_df[\"created_at\"] = datetime.now()\n",
    "\n",
    "# existing_course_codes = []\n",
    "# # Check if 'course' key exists in existing_data\n",
    "# if \"course\" in existing_data:\n",
    "#     existing_course_codes = set(existing_data[\"course\"][\"code\"])\n",
    "\n",
    "# course_df = course_df[~course_df[\"code\"].isin(existing_course_codes)]\n",
    "\n",
    "# store_df(course_df, \"course\")\n",
    "# print(\"Cursos salvos com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wipe_database_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_dict = {'id': ['3047ed31-963f-4f72-977f-bc07126e010f', '3e25e994-04fe-47b5-bb93-b13746b2ee1d', '67355b65-cadf-4e5b-b178-2f325ffe8e6a', 'bc37098a-f50e-44cf-99f6-20349abd7360', '9705e1d4-2966-4b17-95cf-cda120129997', '6709b7f1-2ae8-4e96-aea8-816bcb4411c2', '8fe45895-3761-4bb3-9b17-b806637d638f', '42f17c5c-8dfe-4b69-8007-c5b741e495cb', '221c757d-2b6d-4e3c-8afb-9a1a65788f7d', 'e696737c-229f-4c56-b1ce-68fc0e83ee95', '275cdc83-793a-4b43-8ea4-71d36f3889cc', 'e837b4d1-550b-4b1f-ad2a-efdcb8d427dc', '63592dfa-b49c-4c91-8e72-bd0895c2bbcb', 'db4fa158-cf65-40e2-9b6f-9b181f1aadd7', 'b8ae4a8b-42e5-4d30-9b63-cb8001e59d49', '781c1f2c-99be-4103-81d2-743e6aa49782', 'fbb518a2-bce7-472d-b4b4-6bb32fd81853', '7373fd64-cceb-4e89-8ce4-b7f7fd05b0ed', '97f66c3d-7c1f-470c-9d4b-020d60ffe6aa', '104b5e46-fb02-484c-b208-06a6162c68ad', 'b9a4ea67-9ced-45ca-8de7-8a719b7a3d85', '7dfca9d3-b38d-46a2-86f4-c0cd2018694f', 'a174d77d-dcac-4c7d-a866-3fee3bbf55bb', 'b3899630-d91e-4129-834b-37a1c403d356', '3c70bd25-ff2d-4c31-a187-dda1be9d858a', '183a67c6-e4c5-4440-b258-fa55e63d2df1', '827ff4e4-2a2e-4273-89fa-f4c7e9c5f4dc', '894acc71-5cb8-477a-bbdb-8567f0215c21', '346d1ed8-cc3b-4bf8-8a96-f380c0dd2452', '841543ab-bc3f-489e-91c2-ab9b95e545c3', 'da525bd7-00a5-4c72-b37d-72d87fc7ec6c', '4b6c5510-c0f1-4d39-9379-b4a2c6b47c7d', 'eb3c9444-02a7-4a51-a4f7-67198b2521fa', 'd67c99ef-2656-44eb-b449-0709aa72c43b', '6b7923ec-5850-49d9-a132-c5b257f5fbe4', '1facc180-890f-49a5-b37f-50768b4f07f8', '7de1e05e-244f-49b6-9426-fe438bf09b62', 'ebbc5fb7-9596-4548-86e1-5fac09ebb599', '80904be4-f4fc-4364-9380-849b909ef380', '7d8634bf-1a36-425e-a453-b1b64c599d8e', 'c750d6da-acbb-4d1b-9951-e05dec51782a', 'd73a1748-222d-4d78-93db-25314d6b6db8', 'a56d95e3-ab68-48e7-8425-75b090305142', '61261050-8847-48fb-80e8-e6b726d73655', 'db4a1cb4-22aa-4728-ba87-87d74adb1753', '6792ec98-08b1-419e-8961-a45cdd8fb36e', '4085b8de-35a6-4abb-98f9-2ed9d6603f85', '7e9a6645-ecee-49d5-8e00-1f21863cb019', '2aa595b4-4176-493f-b720-7067206ef986', '0c483044-d409-4022-9b15-5224ba689d6b', '8077d3dd-47e4-4e00-a362-f807e10bda1f', 'bb0598d4-b967-4cca-a558-541191f048b0'], 'code': ['administracao', 'administracao-publica', 'administracao-publica-ead', 'arquitetura-e-urbanismo', 'ciencia-da-computacao', 'ciencia-e-tecnologia-de-alimentos', 'ciencias-economicas', 'direito', 'engenharia-ambiental', 'engenharia-civil', 'engenharia-de-computacao', 'engenharia-de-controle-e-automacao', 'engenharia-de-minas', 'engenharia-de-producao-jm', 'engenharia-de-producao-op', 'engenharia-eletrica', 'engenharia-geologica', 'engenharia-mecanica', 'engenharia-metalurgica', 'engenharia-urbana', 'estatistica', 'farmacia', 'geografia-ead', 'jornalismo', 'matematica-ead', 'medicina', 'museologia', 'musica', 'nutricao', 'pedagogia', 'pedagogia-ead', 'quimica', 'quimica-industrial', 'servico-social', 'sistemas-de-informacao', 'turismo', 'artes-cenicas-bacharelado', 'artes-cenicas-licenciatura', 'ciencias-biologicas-bacharelado', 'ciencias-biologicas-licenciatura', 'educacao-fisica-bacharelado', 'educacao-fisica-licenciatura', 'filosofia-bacharelado', 'filosofia-licenciatura', 'fisica-bacharelado', 'fisica-licenciatura', 'historia-bacharelado', 'historia-licenciatura', 'letras-bacharelado', 'letras-licenciatura', 'matematica-bacharelado', 'matematica-licenciatura'], 'name': ['Administração', 'Administração Pública', 'Administração Pública (EaD)', 'Arquitetura e Urbanismo', 'Ciência da Computação', 'Ciência e Tecnologia de Alimentos', 'Ciências Econômicas', 'Direito', 'Engenharia Ambiental', 'Engenharia Civil', 'Engenharia de Computação', 'Engenharia de Controle e Automação', 'Engenharia de Minas', 'Engenharia de Produção (JM)', 'Engenharia de Produção (OP)', 'Engenharia Elétrica', 'Engenharia Geológica', 'Engenharia Mecânica', 'Engenharia Metalúrgica', 'Engenharia Urbana', 'Estatística', 'Farmácia', 'Geografia (EaD)', 'Jornalismo', 'Matemática (EaD)', 'Medicina', 'Museologia', 'Música', 'Nutrição', 'Pedagogia', 'Pedagogia (EaD)', 'Química', 'Química Industrial', 'Serviço Social', 'Sistemas de Informação', 'Turismo', 'Artes Cênicas (Bacharelado)', 'Artes Cênicas (Licenciatura)', 'Ciências Biológicas (Bacharelado)', 'Ciências Biológicas (Licenciatura)', 'Educação Física (Bacharelado)', 'Educação Física (Licenciatura)', 'Filosofia (Bacharelado)', 'Filosofia (Licenciatura)', 'Física (Bacharelado)', 'Física (Licenciatura)', 'História (Bacharelado)', 'História (Licenciatura)', 'Letras (Bacharelado)', 'Letras (Licenciatura)', 'Matemática (Bacharelado)', 'Matemática (Licenciatura)']}\n",
    "course_df = pd.DataFrame(courses_dict).sort_values(by=\"code\", ascending=True)\n",
    "course_df[\"created_at\"] = datetime.now()\n",
    "\n",
    "existing_course_codes = []\n",
    "# Check if 'course' key exists in existing_data\n",
    "if \"course\" in existing_data:\n",
    "    existing_course_codes = set(existing_data[\"course\"][\"code\"])\n",
    "\n",
    "course_df = course_df[~course_df[\"code\"].isin(existing_course_codes)]\n",
    "\n",
    "store_df(course_df, \"course\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "URL = \"https://zeppelin10.ufop.br/HorarioAulas/\"\n",
    "\n",
    "desired_departments = [\"DECSI\", \"DECEA\", \"DEELT\", \"DEENP\", \"DEETE\"]\n",
    "selected_semester = \"2024/1\"\n",
    "\n",
    "\n",
    "def get_HTML_content_for_semester(url, department=None):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        # Wait for the semester select element to be present\n",
    "        semester_select = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"formPrincipal:anoSemestre\"))\n",
    "        )\n",
    "\n",
    "        # Select the desired semester\n",
    "        select = Select(semester_select)\n",
    "        select.select_by_value(selected_semester)\n",
    "\n",
    "        # Find and click the \"Filtrar\" button\n",
    "        filtrar_button = driver.find_element(By.ID, \"formPrincipal:botaoEnviar\")\n",
    "        filtrar_button.click()\n",
    "\n",
    "        # Wait for the table to be updated\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"formPrincipal:tabela\"))\n",
    "        )\n",
    "\n",
    "        if department:\n",
    "            # If a department is specified, click on it\n",
    "            elem = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, f\"//*[text()='{department}']\"))\n",
    "            )\n",
    "            elem.click()\n",
    "\n",
    "            # Wait for the page to load after clicking the department\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, \"formPrincipal:tabela\"))\n",
    "            )\n",
    "\n",
    "        # Get the updated page source\n",
    "        html_content = driver.page_source\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return BeautifulSoup(html_content, \"lxml\")\n",
    "\n",
    "\n",
    "def parse_schedule_string(schedule_string):\n",
    "    entries = []\n",
    "\n",
    "    if schedule_string == \"\":\n",
    "        return entries\n",
    "\n",
    "    schedule_parts = schedule_string.split(\" / \")\n",
    "\n",
    "    if len(schedule_parts) == 0:\n",
    "        schedule_parts.append(schedule_string)\n",
    "\n",
    "    for part in schedule_parts:\n",
    "        day, time_info = part.split(\" \")\n",
    "        start_time, end_time = time_info.split(\"-\")\n",
    "        class_type = end_time[-2]  # T for theoretical, P for practical\n",
    "        end_time = end_time[:-3]  # Remove the class type from end_time\n",
    "\n",
    "        entry = {\n",
    "            \"day_of_week\": day,\n",
    "            \"start_time\": datetime.strptime(start_time, \"%H:%M\").time(),\n",
    "            \"end_time\": datetime.strptime(end_time, \"%H:%M\").time(),\n",
    "            \"class_type\": class_type,\n",
    "        }\n",
    "        entries.append(entry)\n",
    "\n",
    "    return entries\n",
    "\n",
    "\n",
    "def get_field_list(html_content, field):\n",
    "    field_list = []\n",
    "    table = html_content.find(\"table\", {\"id\": \"formPrincipal:tabela\"})\n",
    "    if table:\n",
    "        tbody = table.find(\"tbody\")\n",
    "        tr_elements = tbody.find_all(\"tr\")\n",
    "\n",
    "        for i, tr in enumerate(tr_elements):\n",
    "            if field == \"descricao\":\n",
    "                span = tr.find(\n",
    "                    \"span\", {\"id\": \"formPrincipal:tabela:{}:{}\".format(i, \"disciplina\")}\n",
    "                )\n",
    "                title = span.find_parent(\"a\").get(\n",
    "                    \"title\"\n",
    "                )  # Extract the 'title' attribute of the parent <a> tag\n",
    "                field_list.append(title)\n",
    "                continue\n",
    "\n",
    "            span = tr.find(\n",
    "                \"span\", {\"id\": \"formPrincipal:tabela:{}:{}\".format(i, field)}\n",
    "            )\n",
    "            field_list.append(span.text)\n",
    "\n",
    "    return field_list\n",
    "\n",
    "\n",
    "def get_departments(existing_data):\n",
    "    soup = get_HTML_content_for_semester(URL)\n",
    "    \n",
    "    departments_list = []\n",
    "    table = soup.find(\"table\", {\"id\": \"formPrincipal:tabela\"})\n",
    "    \n",
    "    # Create a dictionary of existing departments with code as key and id as value\n",
    "    existing_departments = existing_data.get(\"department\", pd.DataFrame())\n",
    "    existing_dept_dict = dict(zip(existing_departments.get(\"code\", []), existing_departments.get(\"id\", [])))\n",
    "    \n",
    "    if table:\n",
    "        tbody = table.find(\"tbody\")\n",
    "        tr_elements = tbody.find_all(\"tr\")\n",
    "\n",
    "        for i, tr in enumerate(tr_elements):\n",
    "            tableCode = tr.find(\n",
    "                \"span\", {\"id\": f\"formPrincipal:tabela:{i}:codigoDepartamento\"}\n",
    "            )\n",
    "            tableName = tr.find(\n",
    "                \"span\", {\"id\": f\"formPrincipal:tabela:{i}:descricao\"}\n",
    "            )\n",
    "            \n",
    "            code = tableCode.text.strip()\n",
    "            name = tableName.text.strip()\n",
    "            \n",
    "            # Use existing ID if department already exists, otherwise generate new UUID\n",
    "            dept_id = existing_dept_dict.get(code, str(uuid.uuid4()))\n",
    "\n",
    "            departments_list.append(\n",
    "                {\n",
    "                    \"id\": dept_id,\n",
    "                    \"code\": code,\n",
    "                    \"name\": name,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        departments_df = pd.DataFrame(departments_list)\n",
    "        departments_df[\"created_at\"] = datetime.now()\n",
    "        return departments_df, departments_list\n",
    "\n",
    "    return pd.DataFrame(), []\n",
    "\n",
    "def get_discipline_tables(departments_list, existing_data):\n",
    "    discipline_dict = {\n",
    "        \"id\": [],\n",
    "        \"code\": [],\n",
    "        \"name\": [],\n",
    "        \"description\": [],\n",
    "        \"department_id\": [],\n",
    "        \"equivalency_group_id\": [],\n",
    "    }\n",
    "    class_dict = {\n",
    "        \"id\": [],\n",
    "        \"class_number\": [],\n",
    "        \"discipline_id\": [],\n",
    "        \"professor\": [],\n",
    "        \"semester\": [],\n",
    "    }\n",
    "    schedule_dict = {\n",
    "        \"id\": [],\n",
    "        \"discipline_class_id\": [],\n",
    "        \"day_of_week\": [],\n",
    "        \"start_time\": [],\n",
    "        \"end_time\": [],\n",
    "        \"class_type\": [],\n",
    "    }\n",
    "\n",
    "    existing_disciplines = existing_data.get(\"discipline\", pd.DataFrame())\n",
    "    existing_discipline_codes = set(existing_disciplines[\"code\"]) if not existing_disciplines.empty else set()\n",
    "    existing_discipline_id_map = dict(zip(existing_disciplines[\"code\"], existing_disciplines[\"id\"])) if not existing_disciplines.empty else {}\n",
    "\n",
    "    existing_classes = existing_data.get(\"discipline_class\", pd.DataFrame())\n",
    "    existing_schedules = existing_data.get(\"discipline_class_schedule\", pd.DataFrame())\n",
    "\n",
    "    discipline_code_to_id = existing_discipline_id_map.copy()\n",
    "    discipline_name_to_info = defaultdict(list)\n",
    "\n",
    "    print(\"\\nBuscando disciplinas\")\n",
    "    with tqdm(total=len(departments_list), desc=\"Progresso\", ascii=True) as pbar:\n",
    "        for department in departments_list:\n",
    "            if department['code'] not in desired_departments:\n",
    "                continue\n",
    "\n",
    "            html_content = get_HTML_content_for_semester(URL, department['code'])\n",
    "            columns_list = [\"codigo\", \"disciplina\", \"descricao\", \"turma\", \"horario\", \"professores\"]\n",
    "            columns_dict_list = {column_name: get_field_list(html_content, column_name) for column_name in columns_list}\n",
    "\n",
    "            for i in range(len(columns_dict_list[\"codigo\"])):\n",
    "                code = columns_dict_list[\"codigo\"][i]\n",
    "                name = columns_dict_list[\"disciplina\"][i]\n",
    "                description = columns_dict_list[\"descricao\"][i]\n",
    "                class_number = columns_dict_list[\"turma\"][i]\n",
    "                professor = columns_dict_list[\"professores\"][i]\n",
    "\n",
    "                if code not in discipline_code_to_id:\n",
    "                    if code not in existing_discipline_codes:\n",
    "                        discipline_id = str(uuid.uuid4())\n",
    "                        discipline_dict[\"id\"].append(discipline_id)\n",
    "                        discipline_dict[\"code\"].append(code)\n",
    "                        discipline_dict[\"name\"].append(name)\n",
    "                        discipline_dict[\"description\"].append(description)\n",
    "                        discipline_dict[\"department_id\"].append(department['id'])\n",
    "                        discipline_dict[\"equivalency_group_id\"].append(None)  # We'll update this later\n",
    "                    else:\n",
    "                        discipline_id = existing_discipline_id_map[code]\n",
    "                    \n",
    "                    discipline_code_to_id[code] = discipline_id\n",
    "\n",
    "                    discipline_name_to_info[name].append({\n",
    "                        \"id\": discipline_id,\n",
    "                        \"code\": code,\n",
    "                        \"department_id\": department['id']\n",
    "                    })\n",
    "                else:\n",
    "                    discipline_id = discipline_code_to_id[code]\n",
    "\n",
    "                # Check if class already exists for this discipline and semester\n",
    "                existing_class = existing_classes[\n",
    "                    (existing_classes[\"discipline_id\"] == discipline_id) &\n",
    "                    (existing_classes[\"class_number\"] == class_number) &\n",
    "                    (existing_classes[\"semester\"] == selected_semester)\n",
    "                ]\n",
    "\n",
    "                if existing_class.empty:\n",
    "                    discipline_class_id = str(uuid.uuid4())\n",
    "                    class_dict[\"id\"].append(discipline_class_id)\n",
    "                    class_dict[\"class_number\"].append(class_number)\n",
    "                    class_dict[\"discipline_id\"].append(discipline_id)\n",
    "                    class_dict[\"professor\"].append(professor)\n",
    "                    class_dict[\"semester\"].append(selected_semester)\n",
    "                else:\n",
    "                    discipline_class_id = existing_class.iloc[0][\"id\"]\n",
    "\n",
    "                schedule_entries = parse_schedule_string(columns_dict_list[\"horario\"][i])\n",
    "                for entry in schedule_entries:\n",
    "                    # Check if schedule already exists for this class\n",
    "                    existing_schedule = existing_schedules[\n",
    "                        (existing_schedules[\"discipline_class_id\"] == discipline_class_id) &\n",
    "                        (existing_schedules[\"day_of_week\"] == entry[\"day_of_week\"]) &\n",
    "                        (existing_schedules[\"start_time\"] == entry[\"start_time\"]) &\n",
    "                        (existing_schedules[\"end_time\"] == entry[\"end_time\"]) &\n",
    "                        (existing_schedules[\"class_type\"] == entry[\"class_type\"])\n",
    "                    ]\n",
    "\n",
    "                    if existing_schedule.empty:\n",
    "                        schedule_dict[\"id\"].append(str(uuid.uuid4()))\n",
    "                        schedule_dict[\"discipline_class_id\"].append(discipline_class_id)\n",
    "                        schedule_dict[\"day_of_week\"].append(entry[\"day_of_week\"])\n",
    "                        schedule_dict[\"start_time\"].append(entry[\"start_time\"])\n",
    "                        schedule_dict[\"end_time\"].append(entry[\"end_time\"])\n",
    "                        schedule_dict[\"class_type\"].append(entry[\"class_type\"])\n",
    "\n",
    "            pbar.set_postfix(info=f\"Salvando disciplinas de {department['code']}...\")\n",
    "            pbar.update(1)\n",
    "            \n",
    "    # Handle equivalencies only for new disciplines\n",
    "    new_disciplines = [\n",
    "        {\"id\": id, \"code\": code, \"name\": name, \"department_id\": dept_id}\n",
    "        for id, code, name, dept_id in zip(\n",
    "            discipline_dict[\"id\"], discipline_dict[\"code\"], \n",
    "            discipline_dict[\"name\"], discipline_dict[\"department_id\"]\n",
    "        )\n",
    "    ]\n",
    "    equivalency_groups = handle_equivalencies(new_disciplines)\n",
    "\n",
    "    existing_equivalency_groups = existing_data.get(\"equivalency_group\", pd.DataFrame())\n",
    "    existing_group_ids = set(existing_equivalency_groups[\"id\"]) if not existing_equivalency_groups.empty else set()\n",
    "\n",
    "    equivalency_group_dict = {\"id\": [], \"created_at\": []}\n",
    "    for group in equivalency_groups:\n",
    "        group_id = str(uuid.uuid4())\n",
    "        if group_id not in existing_group_ids:\n",
    "            equivalency_group_dict[\"id\"].append(group_id)\n",
    "            equivalency_group_dict[\"created_at\"].append(datetime.now())\n",
    "\n",
    "        for discipline in group:\n",
    "            if discipline[\"id\"] in discipline_dict[\"id\"]:\n",
    "                index = discipline_dict[\"id\"].index(discipline[\"id\"])\n",
    "                discipline_dict[\"equivalency_group_id\"][index] = group_id\n",
    "\n",
    "    discipline_df = pd.DataFrame(discipline_dict)\n",
    "    equivalency_group_df = pd.DataFrame(equivalency_group_dict)\n",
    "    class_df = pd.DataFrame(class_dict)\n",
    "    schedule_df = pd.DataFrame(schedule_dict)\n",
    "\n",
    "    currentTime = datetime.now()\n",
    "\n",
    "    discipline_df[\"created_at\"] = currentTime\n",
    "    class_df[\"created_at\"] = currentTime\n",
    "    schedule_df[\"created_at\"] = currentTime\n",
    "\n",
    "    return discipline_df, class_df, schedule_df, equivalency_group_df\n",
    "\n",
    "# Process departments\n",
    "department_df, departments_list = get_departments(existing_data)\n",
    "existing_department_codes = set(existing_data.get(\"department\", {}).get(\"code\", []))\n",
    "print(f\"Existing department codes: {existing_department_codes}\")\n",
    "\n",
    "new_department_df = department_df[~department_df[\"code\"].isin(existing_department_codes)]\n",
    "print(f\"New departments to be added: {new_department_df}\")\n",
    "\n",
    "# Store new departments\n",
    "store_df(new_department_df, \"department\")\n",
    "print(\"New departments saved successfully!\")\n",
    "\n",
    "# Update the departments_list with the correct IDs (including existing ones)\n",
    "departments_list = department_df.to_dict('records')\n",
    "\n",
    "discipline_df, discipline_class_df, discipline_class_schedule_df, equivalency_group_df = get_discipline_tables(departments_list, existing_data)\n",
    "\n",
    "# Store new equivalency groups\n",
    "store_df(equivalency_group_df, 'equivalency_group')\n",
    "print(\"Novos grupos de equivalência salvos com sucesso!\")\n",
    "\n",
    "# Store new disciplines\n",
    "new_discipline_df = discipline_df[~discipline_df[\"code\"].isin(existing_data.get(\"discipline\", {}).get(\"code\", []))]\n",
    "remaining_discipline_ids = set(new_discipline_df[\"id\"])\n",
    "store_df(new_discipline_df, \"discipline\")\n",
    "print(\"Novas disciplinas salvas com sucesso!\")\n",
    "\n",
    "# Store new discipline classes for the current semester\n",
    "existing_classes = existing_data.get(\"discipline_class\", pd.DataFrame())\n",
    "new_discipline_class_df = discipline_class_df[~discipline_class_df[\"id\"].isin(existing_classes[\"id\"])]\n",
    "store_df(new_discipline_class_df, \"discipline_class\")\n",
    "\n",
    "# Store new discipline class schedules\n",
    "existing_schedules = existing_data.get(\"discipline_class_schedule\", pd.DataFrame())\n",
    "new_discipline_class_schedule_df = discipline_class_schedule_df[~discipline_class_schedule_df[\"id\"].isin(existing_schedules[\"id\"])]\n",
    "store_df(new_discipline_class_schedule_df, \"discipline_class_schedule\")\n",
    "\n",
    "print(\"Classes e horários das disciplinas salvos com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import re\n",
    "\n",
    "code_pattern = r\"[A-Z]{3}\\d{3}\"\n",
    "subject_pattern = r\"\\b[A-Z]+\\b\"\n",
    "classes_pattern = r\"^(T P|T|P)$\"\n",
    "prerequisite_pattern = r\"[A-Z]{3}\\d{3}|\\d+\\s+horas\"\n",
    "chs_che_pattern = r\"^\\d+\\/\\d+$\"\n",
    "\n",
    "discipline_course_dict = {\"id\": [], \"discipline_id\": [], \"course_id\": [], \"period\": [], \"mandatory\": [], \"created_at\": []}\n",
    "prerequisite_dict = {\"id\": [], \"discipline_course_id\": [], \"prerequisite_discipline_id\": [], \"created_at\": []}\n",
    "empty_discipline_course_df = pd.DataFrame(data=discipline_course_dict)\n",
    "empty_prerequisite_df = pd.DataFrame(data=prerequisite_dict)\n",
    "\n",
    "def get_col_idx(df_value, pattern):\n",
    "    indexes = []\n",
    "    for i, item in enumerate(df_value):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        match = re.search(pattern, str(item), re.UNICODE)\n",
    "        if match is not None:\n",
    "            indexes.append(i)\n",
    "\n",
    "    return indexes\n",
    "\n",
    "\n",
    "def get_prerequisites(df_value):\n",
    "    prerequisites = []\n",
    "    prereq_idx = get_col_idx(df_value, prerequisite_pattern)\n",
    "    if len(prereq_idx) > 0:\n",
    "        prerequisites = [df_value[i] for i in prereq_idx]\n",
    "\n",
    "    return format_prerequisites(prerequisites)\n",
    "\n",
    "\n",
    "def get_discipline(df_value):\n",
    "    subject_idx = get_col_idx(df_value, subject_pattern)\n",
    "    if len(subject_idx) > 0:\n",
    "        return re.sub(code_pattern, \"\", df_value[subject_idx[0]])\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_chs_che(df_value):\n",
    "    chs_che_idx = get_col_idx(df_value, chs_che_pattern)\n",
    "\n",
    "    if len(chs_che_idx) > 0:\n",
    "        chs_che_list = df_value[chs_che_idx[0]].split(\"/\")\n",
    "        return tuple(map(int, chs_che_list))\n",
    "\n",
    "    return (\"\", \"\")\n",
    "\n",
    "\n",
    "def get_classes(df_value, classes_idx):\n",
    "    classes = []\n",
    "    if len(classes_idx) > 0:\n",
    "        classes = [df_value[i] for i in classes_idx]\n",
    "        return \" \".join(classes)\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def get_period(df_value, mandatory):\n",
    "    if not mandatory or not df_value[0]:\n",
    "        return \"\"\n",
    "\n",
    "    for item in reversed(df_value):\n",
    "        if item:\n",
    "            return int(item)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_cha(df_value, chs):\n",
    "    if not chs:\n",
    "        return \"\"\n",
    "\n",
    "    chs_alt = chs * 1.2\n",
    "\n",
    "    if len(df_value) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    for text in df_value:\n",
    "        try:\n",
    "            formatted_text = int(text)\n",
    "            if formatted_text == chs or formatted_text == chs_alt:\n",
    "                return formatted_text\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def format_prerequisites(df_value):\n",
    "    if len(df_value) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    requisites = []\n",
    "    for text in df_value:\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        matches = re.findall(code_pattern, text)\n",
    "        requisites.extend(matches)\n",
    "\n",
    "    joined_matches = \" \".join(requisites)\n",
    "    return joined_matches\n",
    "\n",
    "\n",
    "def get_prerequisite_df(discipline_course_df):\n",
    "    prerequisite_dict = {\"id\": [], \"discipline_course_id\": [], \"prerequisite_discipline_id\": []}\n",
    "    discipline_course_dict = discipline_course_df.to_dict('records')\n",
    "\n",
    "    for discipline_course in discipline_course_dict:   \n",
    "        prerequisites = discipline_course['prerequisites'].split()\n",
    "         # create a dictionary where the keys are the codes and the values are the ids\n",
    "        id_map = discipline_df.set_index('code')['id'].to_dict()\n",
    "\n",
    "        # use the dictionary to map the codes to ids\n",
    "        discipline_ids = [id_map[code] for code in prerequisites if code in id_map]\n",
    "        if len(discipline_ids) > 0:\n",
    "            for prerequisite in discipline_ids:\n",
    "                prerequisite_id = uuid.uuid4()\n",
    "                prerequisite_dict['id'].append(prerequisite_id)\n",
    "                prerequisite_dict['discipline_course_id'].append(discipline_course['id'])\n",
    "                prerequisite_dict['prerequisite_discipline_id'].append(prerequisite)\n",
    "   \n",
    "\n",
    "    prerequisite_df = pd.DataFrame(prerequisite_dict)\n",
    "    return prerequisite_df\n",
    "\n",
    "\n",
    "def get_discipline_course_tables(df, course_id, mandatory):\n",
    "    df = df.replace({r\"\\r\": \" \"}, regex=True)\n",
    "    df_struct = {\"id\": [], \"discipline_id\": [], \"period\": [], \"prerequisites\": []}\n",
    "    discipline_course_df = pd.DataFrame(data=df_struct)\n",
    "\n",
    "    iterIdx = -1\n",
    "\n",
    "    for idx, value in enumerate(df.values):\n",
    "        if idx == 0:\n",
    "            iterIdx = -1\n",
    "            discipline_course_df.at[0, \"id\"] = \"\"\n",
    "            discipline_course_df.at[0, \"discipline_id\"] = \"\"\n",
    "            discipline_course_df.at[0, \"period\"] = \"\"\n",
    "            discipline_course_df.at[0, \"prerequisites\"] = \"\"\n",
    "            continue\n",
    "\n",
    "        discipline_ids = discipline_df[discipline_df['code'] == value[0]]['id']\n",
    "        discipline_course_id = ''\n",
    "        discipline_id = ''\n",
    "\n",
    "        if(len(discipline_ids.values) > 0):\n",
    "            discipline_id = discipline_ids.values[0]\n",
    "        \n",
    "        if value[0]:\n",
    "            discipline_course_id = str(uuid.uuid4())\n",
    "\n",
    "        discipline_course_df.at[idx, \"id\"] = discipline_course_id\n",
    "        discipline_course_df.at[idx, \"discipline_id\"] = discipline_id\n",
    "        discipline_course_df.at[idx, \"period\"] = get_period(value, mandatory)\n",
    "        discipline_course_df.at[idx, \"prerequisites\"] = get_prerequisites(value)\n",
    "\n",
    "        if value[0] != \"\":\n",
    "            iterIdx = -1\n",
    "            continue\n",
    "\n",
    "        if iterIdx == -1:\n",
    "            iterIdx = idx - 1\n",
    "\n",
    "        discipline_course_df.loc[iterIdx, :] = [\n",
    "            f\"{item1} {item2}\".strip()\n",
    "            for item1, item2 in zip(\n",
    "                discipline_course_df.values[iterIdx], discipline_course_df.values[idx]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    discipline_course_df.drop(\n",
    "        discipline_course_df[discipline_course_df[\"discipline_id\"] == \"\"].index,\n",
    "        inplace=True,\n",
    "    )\n",
    "    discipline_course_df[\"mandatory\"] = mandatory\n",
    "    discipline_course_df[\"course_id\"] = course_id\n",
    "    discipline_course_df['period'] = discipline_course_df['period'].replace(\"\", 0)\n",
    "\n",
    "    prerequisite_df = pd.DataFrame()\n",
    "    if not discipline_course_df.empty:\n",
    "        prerequisite_df = get_prerequisite_df(discipline_course_df)\n",
    "\n",
    "    discipline_course_df.drop(\"prerequisites\", axis=1, inplace=True)\n",
    "    return discipline_course_df, prerequisite_df\n",
    "\n",
    "\n",
    "def scrape_table_from_pdf(pdf_path):\n",
    "    \n",
    "    # Read the table from the PDF file\n",
    "    df_list = tabula.read_pdf(pdf_path, pages=\"all\")\n",
    "\n",
    "    course_code = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    course_ids = course_df[course_df['code'] == course_code]['id']\n",
    "\n",
    "    \n",
    "    if(len(course_ids.values) == 0):\n",
    "        \n",
    "        return empty_discipline_course_df, empty_prerequisite_df\n",
    "\n",
    "    course_id = course_ids.values[0]\n",
    "    discipline_course_dfs = []\n",
    "    prerequisite_dfs = []\n",
    "\n",
    "    for df in df_list:\n",
    "        df.fillna(\"\", inplace=True)\n",
    "        header = df.columns.to_list()\n",
    "       \n",
    "        # Filter and select the desired columns based on the header\n",
    "        if \"DISCIPLINAS OBRIGATÓRIAS\" in header:\n",
    "            discipline_course_df, prerequisite_df = get_discipline_course_tables(\n",
    "                df, course_id, True\n",
    "            )\n",
    "            discipline_course_dfs.append(discipline_course_df)\n",
    "            prerequisite_dfs.append(prerequisite_df)\n",
    "\n",
    "        elif (\n",
    "            \"DISCIPLINAS ELETIVAS\" in header\n",
    "            or \"DISCIPLINAS ELETIVAS PRÉ-REQUISITO\" in header\n",
    "        ):\n",
    "            discipline_course_df, prerequisite_df = get_discipline_course_tables(\n",
    "                df, course_id, False\n",
    "            )\n",
    "            discipline_course_dfs.append(discipline_course_df)\n",
    "            prerequisite_dfs.append(prerequisite_df)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    combined_discipline_course_df = pd.concat(discipline_course_dfs, ignore_index=True)\n",
    "    combined_prerequisite_df = pd.concat(prerequisite_dfs, ignore_index=True)\n",
    "\n",
    "    discipline_course_df = combined_discipline_course_df[\n",
    "        combined_discipline_course_df[\"discipline_id\"].isin(discipline_df[\"id\"])\n",
    "    ]\n",
    "\n",
    "    prerequisite_df = combined_prerequisite_df\n",
    "    if not combined_prerequisite_df.empty:\n",
    "        prerequisite_df = combined_prerequisite_df[\n",
    "            combined_prerequisite_df[\"discipline_course_id\"].isin(\n",
    "                discipline_course_df[\"id\"]\n",
    "            )\n",
    "        ]\n",
    "    discipline_course_df[\"created_at\"] = datetime.now()\n",
    "    prerequisite_df[\"created_at\"] = datetime.now()\n",
    "\n",
    "    return discipline_course_df, prerequisite_df\n",
    "\n",
    "\n",
    "files = os.listdir(pdfs_folder_path)\n",
    "pdf_files = [\n",
    "    os.path.join(pdfs_folder_path, file) for file in files if file.endswith(\".pdf\")\n",
    "]\n",
    "\n",
    "for pdf_file in [\n",
    "    \"./courses_pdfs/engenharia-de-computacao.pdf\",\n",
    "    \"./courses_pdfs/engenharia-de-producao-jm.pdf\",\n",
    "    \"./courses_pdfs/sistemas-de-informacao.pdf\",\n",
    "    \"./courses_pdfs/engenharia-eletrica.pdf\",\n",
    "]:\n",
    "    print(f\"Buscando disciplinas de {pdf_file}\")\n",
    "    discipline_course_df, prerequisite_df = scrape_table_from_pdf(pdf_file)\n",
    "    \n",
    "    discipline_course_df = discipline_course_df[discipline_course_df['discipline_id'].isin(remaining_discipline_ids)]\n",
    "    store_df(discipline_course_df, 'discipline_course')\n",
    "    print(\"Disciplinas do curso armazenadas com sucesso!\")\n",
    "\n",
    "    remaining_discipline_course_ids = set(discipline_course_df['id'])\n",
    "    prerequisite_df = prerequisite_df[prerequisite_df['discipline_course_id'].isin(remaining_discipline_course_ids)]\n",
    "    store_df(prerequisite_df, 'prerequisite')\n",
    "    print(\"Prerequisitos armazenados com sucesso!\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
