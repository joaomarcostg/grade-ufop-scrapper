{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (4.65.0)\n",
      "Requirement already satisfied: sqlalchemy in ./venv/lib/python3.9/site-packages (2.0.19)\n",
      "Requirement already satisfied: tabula-py in ./venv/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: psycopg2-binary in ./venv/lib/python3.9/site-packages (2.9.6)\n",
      "Requirement already satisfied: lxml in ./venv/lib/python3.9/site-packages (4.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./venv/lib/python3.9/site-packages (from sqlalchemy) (4.7.1)\n",
      "Requirement already satisfied: pandas>=0.25.3 in ./venv/lib/python3.9/site-packages (from tabula-py) (2.0.3)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (from tabula-py) (1.25.1)\n",
      "Requirement already satisfied: distro in ./venv/lib/python3.9/site-packages (from tabula-py) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.9/site-packages (from pandas>=0.25.3->tabula-py) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.9/site-packages (from pandas>=0.25.3->tabula-py) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/joaomarcostorresgardingo/grade-ufop-scrapper/venv/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup \n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "%pip install tqdm sqlalchemy tabula-py psycopg2-binary lxml\n",
    "\n",
    "\n",
    "\n",
    "# Create the \"tables\" folder if it doesn't exist\n",
    "tables_folder_path = \"./tables\"\n",
    "if not os.path.exists(tables_folder_path):\n",
    "    os.makedirs(tables_folder_path)\n",
    "\n",
    "\n",
    "# Create the \"matrizes\" folder if it doesn't exist\n",
    "pdfs_folder_path = \"./courses_pdfs\"\n",
    "if not os.path.exists(pdfs_folder_path):\n",
    "    os.makedirs(pdfs_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['department', 'discipline', 'discipline_course', 'course', 'discipline_class', 'discipline_class_schedule', 'prerequisite']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "db_name = 'gradeufop_db'\n",
    "username = 'postgres'\n",
    "password = '12345678'\n",
    "\n",
    "# Replace 'localhost' with the appropriate host if your PostgreSQL server is running on a different machine\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "\n",
    "# Create a connection to the PostgreSQL database\n",
    "conn_str = f\"postgresql://{username}:{password}@{host}:{port}/{db_name}\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# create inspector\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# get table names\n",
    "table_names = inspector.get_table_names()\n",
    "print(table_names)\n",
    "\n",
    "# initialize an empty dictionary to hold the data\n",
    "existing_data = {}\n",
    "\n",
    "# iterate over all table names\n",
    "for table in table_names:\n",
    "    # read the data from the table and save it to the dictionary\n",
    "    existing_data[table] = pd.read_sql(f'SELECT * FROM {table}', engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def store_df(df, table):\n",
    "    # Store the DataFrame in database\n",
    "    df.to_sql(table, engine, index=False, if_exists='append')\n",
    "    \n",
    "    # Append the DataFrame to its CSV file\n",
    "    df.to_csv(\n",
    "        f\"{tables_folder_path}/{table}.csv\",\n",
    "        mode=\"a\",\n",
    "        header=not os.path.exists(f\"{tables_folder_path}/{table}.csv\"),\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def format_course_name(text):\n",
    "    # Remove accent marks\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "    \n",
    "    # Replace symbols with a hyphen\n",
    "    text = re.sub(r'[^a-zA-Z0-9]+', '-', text)\n",
    "    \n",
    "    # Remove leading and trailing hyphens\n",
    "    text = text.strip('-')\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busca cursos e salva os .pdfs na pasta /matrizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando a lista de cursos da UFOP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progresso: 100%|##########| 44/44 [00:00<00:00, 47.80it/s, curso=Turismo]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buscando os links .pdf ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progresso: 100%|##########| 44/44 [00:42<00:00,  1.02it/s, curso=Turismo]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salvando os arquivos .pdf dos cursos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progresso: 100%|##########| 52/52 [00:21<00:00,  2.47it/s, salvando=turismo.pdf]                           \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "# Set up Chrome driver service\n",
    "chromedriver_path = (\n",
    "    \"./chromedriver\"  # Replace with the path to your chromedriver executable\n",
    ")\n",
    "service = Service()\n",
    "\n",
    "# Set up Chrome driver\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Navigate to the URL\n",
    "url = \"https://www.escolha.ufop.br/cursos\"\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# Find elements with class \"ufop-glossary-row\"\n",
    "elements = driver.find_elements(By.CLASS_NAME, \"ufop-glossary-row\")\n",
    "\n",
    "# Extract the href links from child anchor 'a' tags\n",
    "links = []\n",
    "courses_dict = {\"id\": [], \"code\": [], \"name\": []}\n",
    "\n",
    "print(\"Buscando a lista de cursos da UFOP...\")\n",
    "with tqdm(total=len(elements), desc=\"Progresso\", ascii=True) as pbar:\n",
    "    for element in elements:\n",
    "        link_element = element.find_element(By.TAG_NAME, \"a\")\n",
    "        href = link_element.get_attribute(\"href\")\n",
    "        links.append(href)\n",
    "\n",
    "        courses_dict[\"id\"].append(str(uuid.uuid4()))\n",
    "        courses_dict[\"code\"].append(format_course_name(link_element.text))\n",
    "        courses_dict[\"name\"].append(link_element.text)\n",
    "        pbar.set_postfix(curso=f\"{link_element.text}\")\n",
    "        pbar.update(1)\n",
    "\n",
    "indexes_to_delete = []\n",
    "course_pdfs = []\n",
    "\n",
    "# Navigate to each link and download PDF files\n",
    "print(\"\\nBuscando os links .pdf ...\")\n",
    "with tqdm(total=len(links), desc=\"Progresso\", ascii=True) as pbar:\n",
    "    for i, link in enumerate(links):\n",
    "        driver.get(link)\n",
    "\n",
    "        matriz_elements = driver.find_elements(\n",
    "            By.CLASS_NAME, \"field-name-field-matriz-curricular\"\n",
    "        )\n",
    "\n",
    "        for element in matriz_elements:\n",
    "            link_elements = element.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "            if len(link_elements) == 1:\n",
    "                href = link_elements[0].get_attribute(\"href\")\n",
    "                course_pdfs.append({\"course\": courses_dict[\"code\"][i], \"link\": href})\n",
    "                continue\n",
    "\n",
    "            for link_element in link_elements:\n",
    "                href = link_element.get_attribute(\"href\")\n",
    "                course_type = link_element.text\n",
    "                course_name = f\"{courses_dict['name'][i]} ({course_type})\"\n",
    "                course_code = format_course_name(course_name)\n",
    "                courses_dict[\"id\"].append(str(uuid.uuid4()))\n",
    "                courses_dict[\"name\"].append(course_name)\n",
    "                courses_dict[\"code\"].append(course_code)\n",
    "\n",
    "                course_pdfs.append({\"course\": course_code, \"link\": href})\n",
    "            indexes_to_delete.append(i)\n",
    "\n",
    "        pbar.set_postfix(curso=f\"{courses_dict['name'][i]}\")\n",
    "        pbar.update(1)\n",
    "\n",
    "courses_dict[\"id\"] = [\n",
    "    item for i, item in enumerate(courses_dict[\"id\"]) if i not in indexes_to_delete\n",
    "]\n",
    "courses_dict[\"code\"] = [\n",
    "    item for i, item in enumerate(courses_dict[\"code\"]) if i not in indexes_to_delete\n",
    "]\n",
    "courses_dict[\"name\"] = [\n",
    "    item for i, item in enumerate(courses_dict[\"name\"]) if i not in indexes_to_delete\n",
    "]\n",
    "\n",
    "valid_pdf_substrings = [\".pdf\", \"codCurso=\"]\n",
    "for pdf in course_pdfs:\n",
    "    import os\n",
    "\n",
    "print(\"\\nSalvando os arquivos .pdf dos cursos\")\n",
    "with tqdm(total=len(course_pdfs), desc=\"Progresso\", ascii=True) as pbar:\n",
    "\n",
    "    for pdf in course_pdfs:\n",
    "        if any(text in pdf[\"link\"] for text in valid_pdf_substrings):\n",
    "            response = requests.get(pdf[\"link\"])\n",
    "            parsed_url = urlparse(pdf[\"link\"])\n",
    "            filename = f\"{pdf['course']}.pdf\"\n",
    "            file_path = os.path.join(pdfs_folder_path, filename)\n",
    "\n",
    "            # Check if the file already exists in the folder\n",
    "            if not os.path.exists(file_path):\n",
    "                with open(file_path, \"wb\") as file:\n",
    "                    file.write(response.content)\n",
    "        \n",
    "        pbar.set_postfix(salvando=f\"{pdf['course']}.pdf\")\n",
    "        pbar.update(1)\n",
    "        \n",
    "# Quit the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salva os cursos encontrados no banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cursos salvos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "course_df = pd.DataFrame(courses_dict).sort_values(by='code', ascending=True)\n",
    "course_df['created_at'] = datetime.now()\n",
    "\n",
    "existing_course_codes = set(existing_data['course']['code'])\n",
    "course_df = course_df[~course_df['code'].isin(existing_course_codes)]\n",
    "\n",
    "store_df(course_df, 'course')\n",
    "\n",
    "print(\"Cursos salvos com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Departamentos salvos com sucesso!\n",
      "\n",
      "Buscando disciplinas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progresso:  11%|#         | 5/47 [00:10<01:27,  2.09s/it, info=Salvando disciplinas de DEETE...]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dados armazenados com sucesso!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "URL = \"https://zeppelin10.ufop.br/HorarioAulas/\"\n",
    "\n",
    "desired_departments = [\"DECSI\", \"DECEA\", \"DEELT\", \"DEENP\", \"DEETE\"]\n",
    "semester = \"23.1\"\n",
    "\n",
    "\n",
    "def get_HTML_content(URL, department):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(URL)\n",
    "    elem = driver.find_element(By.XPATH, \"//*[text()='{}']\".format(department))\n",
    "    elem.click()\n",
    "    URL = driver.current_url\n",
    "    html_source = driver.page_source\n",
    "    soup = BeautifulSoup(html_source, \"lxml\")\n",
    "    driver.quit()\n",
    "    return soup\n",
    "\n",
    "\n",
    "def parse_schedule_string(schedule_string):\n",
    "    entries = []\n",
    "    \n",
    "    if schedule_string == '':\n",
    "        return entries\n",
    "    \n",
    "    schedule_parts = schedule_string.split(\" / \")\n",
    "    \n",
    "    if len(schedule_parts) == 0:\n",
    "        schedule_parts.append(schedule_string)\n",
    "\n",
    "    for part in schedule_parts:\n",
    "        day, time_info = part.split(\" \")\n",
    "        start_time, end_time = time_info.split(\"-\")\n",
    "        class_type = end_time[-2]  # T for theoretical, P for practical\n",
    "        end_time = end_time[:-3]  # Remove the class type from end_time\n",
    "\n",
    "        entry = {\n",
    "            \"day_of_week\": day,\n",
    "            \"start_time\":  datetime.strptime(start_time, \"%H:%M\").time(),\n",
    "            \"end_time\": datetime.strptime(end_time, \"%H:%M\").time(),\n",
    "            \"class_type\": class_type,\n",
    "        }\n",
    "        entries.append(entry)\n",
    "\n",
    "    return entries\n",
    "\n",
    "\n",
    "def get_field_list(html_content, field):\n",
    "    field_list = []\n",
    "    table = html_content.find(\"table\", {\"id\": \"formPrincipal:tabela\"})\n",
    "    if table:\n",
    "        tbody = table.find(\"tbody\")\n",
    "        tr_elements = tbody.find_all(\"tr\")\n",
    "\n",
    "        for i, tr in enumerate(tr_elements):\n",
    "            if field == \"descricao\":\n",
    "                span = tr.find(\n",
    "                    \"span\", {\"id\": \"formPrincipal:tabela:{}:{}\".format(i, \"disciplina\")}\n",
    "                )\n",
    "                title = span.find_parent(\"a\").get(\n",
    "                    \"title\"\n",
    "                )  # Extract the 'title' attribute of the parent <a> tag\n",
    "                field_list.append(title)\n",
    "                continue\n",
    "\n",
    "            span = tr.find(\n",
    "                \"span\", {\"id\": \"formPrincipal:tabela:{}:{}\".format(i, field)}\n",
    "            )\n",
    "            field_list.append(span.text)\n",
    "\n",
    "    return field_list\n",
    "\n",
    "\n",
    "def get_departments():\n",
    "    r = requests.get(URL)\n",
    "    departments_list = []\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")  # Use 'html.parser' as the parser\n",
    "\n",
    "    # Find the table with the specified id\n",
    "    table = soup.find(\"table\", {\"id\": \"formPrincipal:tabela\"})\n",
    "    if table:\n",
    "        tbody = table.find(\"tbody\")\n",
    "\n",
    "        # Find all <tr> elements within <tbody>\n",
    "        tr_elements = tbody.find_all(\"tr\")\n",
    "\n",
    "        for i, tr in enumerate(tr_elements):\n",
    "            tableCode = tr.find(\n",
    "                \"span\", {\"id\": \"formPrincipal:tabela:{}:codigoDepartamento\".format(i)}\n",
    "            )\n",
    "            tableName = tr.find(\n",
    "                \"span\", {\"id\": \"formPrincipal:tabela:{}:descricao\".format(i)}\n",
    "            )\n",
    "\n",
    "            \n",
    "            departments_list.append(\n",
    "                {\"id\": uuid.uuid4(), \"code\": tableCode.text.strip(), \"name\": tableName.text.strip()}\n",
    "            )\n",
    "            \n",
    "\n",
    "        departments_df = pd.DataFrame(departments_list)\n",
    "        departments_df[\"created_at\"] = datetime.now()\n",
    "        return departments_df, departments_list\n",
    "\n",
    "\n",
    "def get_discipline_tables(departments_list):\n",
    "    discipline_dict = {\"id\": [], \"code\": [], \"name\": [], \"description\": [], \"department_id\": []}\n",
    "    class_dict = {\n",
    "        \"id\": [],\n",
    "        \"class_number\": [],\n",
    "        \"discipline_id\": [],\n",
    "        \"professor\": [],\n",
    "    }\n",
    "    schedule_dict = {\n",
    "        \"id\": [],\n",
    "        \"discipline_class_id\": [],\n",
    "        \"day_of_week\": [],\n",
    "        \"start_time\": [],\n",
    "        \"end_time\": [],\n",
    "        \"class_type\": [],\n",
    "    }\n",
    "\n",
    "    discipline_code_to_id = {}  # To store unique IDs for each discipline code\n",
    "    \n",
    "    print(\"\\nBuscando disciplinas\")\n",
    "    with tqdm(total=len(departments_list), desc=\"Progresso\", ascii=True) as pbar:\n",
    "        for department in departments_list:\n",
    "            if department['code'] not in desired_departments:\n",
    "                continue\n",
    "\n",
    "            html_content = get_HTML_content(URL, department['code'])\n",
    "            columns_list = [\n",
    "                \"codigo\",\n",
    "                \"disciplina\",\n",
    "                \"descricao\",\n",
    "                \"turma\",\n",
    "                \"horario\",\n",
    "                \"professores\",\n",
    "            ]\n",
    "            columns_dict_list = {column_name: get_field_list(html_content, column_name) for column_name in columns_list}\n",
    "\n",
    "            for i in range(len(columns_dict_list[\"codigo\"])):\n",
    "                code = columns_dict_list[\"codigo\"][i]\n",
    "                if code not in discipline_code_to_id:\n",
    "                    discipline_id = str(uuid.uuid4())\n",
    "                    discipline_code_to_id[code] = discipline_id\n",
    "                    discipline_dict[\"id\"].append(discipline_id)\n",
    "                    discipline_dict[\"code\"].append(code)\n",
    "                    discipline_dict[\"name\"].append(columns_dict_list[\"disciplina\"][i])\n",
    "                    discipline_dict[\"description\"].append(columns_dict_list[\"descricao\"][i])\n",
    "                    discipline_dict[\"department_id\"].append(department['id'])\n",
    "\n",
    "                discipline_class_id = str(uuid.uuid4())\n",
    "                class_dict[\"id\"].append(discipline_class_id)\n",
    "                class_dict[\"class_number\"].append(columns_dict_list[\"turma\"][i])\n",
    "                class_dict[\"discipline_id\"].append(discipline_code_to_id[code])\n",
    "                class_dict[\"professor\"].append(columns_dict_list[\"professores\"][i])\n",
    "\n",
    "                schedule_entries = parse_schedule_string(columns_dict_list[\"horario\"][i])\n",
    "                for entry in schedule_entries:\n",
    "                    schedule_dict[\"id\"].append(str(uuid.uuid4()))\n",
    "                    schedule_dict[\"discipline_class_id\"].append(discipline_class_id)\n",
    "                    schedule_dict[\"day_of_week\"].append(entry[\"day_of_week\"])\n",
    "                    schedule_dict[\"start_time\"].append(entry[\"start_time\"])\n",
    "                    schedule_dict[\"end_time\"].append(entry[\"end_time\"])\n",
    "                    schedule_dict[\"class_type\"].append(entry[\"class_type\"])\n",
    "            \n",
    "            pbar.set_postfix(info=f\"Salvando disciplinas de {department['code']}...\")\n",
    "            pbar.update(1)\n",
    "            \n",
    "    discipline_df = pd.DataFrame(discipline_dict)\n",
    "    class_df = pd.DataFrame(class_dict)\n",
    "    schedule_df = pd.DataFrame(schedule_dict)\n",
    "\n",
    "    currentTime = datetime.now()\n",
    "\n",
    "    discipline_df[\"created_at\"] = currentTime\n",
    "    class_df[\"created_at\"] = currentTime\n",
    "    class_df[\"semester\"] = semester\n",
    "    schedule_df[\"created_at\"] = currentTime\n",
    "    return discipline_df, class_df, schedule_df\n",
    "\n",
    "\n",
    "department_df, departments_list = get_departments()\n",
    "existing_department_codes = set(existing_data['department']['code'])\n",
    "department_df = department_df[~department_df['code'].isin(existing_department_codes)]\n",
    "store_df(department_df, 'department')\n",
    "print(\"Departamentos salvos com sucesso!\")\n",
    "\n",
    "(\n",
    "    discipline_df,\n",
    "    discipline_class_df,\n",
    "    discipline_class_schedule_df,\n",
    ") = get_discipline_tables(departments_list)\n",
    "\n",
    "existing_discipline_codes = set(existing_data['discipline']['code'])\n",
    "discipline_df = discipline_df[~discipline_df['code'].isin(existing_discipline_codes)]\n",
    "store_df(discipline_df, 'discipline')\n",
    "\n",
    "remaining_discipline_ids = set(discipline_df['id'])\n",
    "discipline_class_df = discipline_class_df[discipline_class_df['discipline_id'].isin(remaining_discipline_ids)]\n",
    "store_df(discipline_class_df, 'discipline_class')\n",
    "\n",
    "remaining_discipline_class_ids = set(discipline_class_df['id'])\n",
    "discipline_class_schedule_df = discipline_class_schedule_df[discipline_class_schedule_df['discipline_class_id'].isin(remaining_discipline_class_ids)]\n",
    "store_df(discipline_class_schedule_df, 'discipline_class_schedule')\n",
    "\n",
    "print(\"\\nDados armazenados com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando disciplinas de ./courses_pdfs/engenharia-de-computacao.pdf\n",
      "Disciplinas do curso armazenadas com sucesso!\n",
      "Prerequisitos armazenados com sucesso!\n",
      "\n",
      "Buscando disciplinas de ./courses_pdfs/engenharia-de-producao-jm.pdf\n",
      "Disciplinas do curso armazenadas com sucesso!\n",
      "Prerequisitos armazenados com sucesso!\n",
      "\n",
      "Buscando disciplinas de ./courses_pdfs/sistemas-de-informacao.pdf\n",
      "Disciplinas do curso armazenadas com sucesso!\n",
      "Prerequisitos armazenados com sucesso!\n",
      "\n",
      "Buscando disciplinas de ./courses_pdfs/engenharia-eletrica.pdf\n",
      "Disciplinas do curso armazenadas com sucesso!\n",
      "Prerequisitos armazenados com sucesso!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import re\n",
    "\n",
    "code_pattern = r\"[A-Z]{3}\\d{3}\"\n",
    "subject_pattern = r\"\\b[A-Z]+\\b\"\n",
    "classes_pattern = r\"^(T P|T|P)$\"\n",
    "prerequisite_pattern = r\"[A-Z]{3}\\d{3}|\\d+\\s+horas\"\n",
    "chs_che_pattern = r\"^\\d+\\/\\d+$\"\n",
    "\n",
    "discipline_course_dict = {\"id\": [], \"discipline_id\": [], \"course_id\": [], \"period\": [], \"mandatory\": [], \"created_at\": []}\n",
    "prerequisite_dict = {\"id\": [], \"discipline_course_id\": [], \"prerequisite_discipline_id\": [], \"created_at\": []}\n",
    "empty_discipline_course_df = pd.DataFrame(data=discipline_course_dict)\n",
    "empty_prerequisite_df = pd.DataFrame(data=prerequisite_dict)\n",
    "\n",
    "def get_col_idx(df_value, pattern):\n",
    "    indexes = []\n",
    "    for i, item in enumerate(df_value):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        match = re.search(pattern, str(item), re.UNICODE)\n",
    "        if match is not None:\n",
    "            indexes.append(i)\n",
    "\n",
    "    return indexes\n",
    "\n",
    "\n",
    "def get_prerequisites(df_value):\n",
    "    prerequisites = []\n",
    "    prereq_idx = get_col_idx(df_value, prerequisite_pattern)\n",
    "    if len(prereq_idx) > 0:\n",
    "        prerequisites = [df_value[i] for i in prereq_idx]\n",
    "\n",
    "    return format_prerequisites(prerequisites)\n",
    "\n",
    "\n",
    "def get_discipline(df_value):\n",
    "    subject_idx = get_col_idx(df_value, subject_pattern)\n",
    "    if len(subject_idx) > 0:\n",
    "        return re.sub(code_pattern, \"\", df_value[subject_idx[0]])\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_chs_che(df_value):\n",
    "    chs_che_idx = get_col_idx(df_value, chs_che_pattern)\n",
    "\n",
    "    if len(chs_che_idx) > 0:\n",
    "        chs_che_list = df_value[chs_che_idx[0]].split(\"/\")\n",
    "        return tuple(map(int, chs_che_list))\n",
    "\n",
    "    return (\"\", \"\")\n",
    "\n",
    "\n",
    "def get_classes(df_value, classes_idx):\n",
    "    classes = []\n",
    "    if len(classes_idx) > 0:\n",
    "        classes = [df_value[i] for i in classes_idx]\n",
    "        return \" \".join(classes)\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def get_period(df_value, mandatory):\n",
    "    if not mandatory or not df_value[0]:\n",
    "        return \"\"\n",
    "\n",
    "    for item in reversed(df_value):\n",
    "        if item:\n",
    "            return int(item)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_cha(df_value, chs):\n",
    "    if not chs:\n",
    "        return \"\"\n",
    "\n",
    "    chs_alt = chs * 1.2\n",
    "\n",
    "    if len(df_value) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    for text in df_value:\n",
    "        try:\n",
    "            formatted_text = int(text)\n",
    "            if formatted_text == chs or formatted_text == chs_alt:\n",
    "                return formatted_text\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def format_prerequisites(df_value):\n",
    "    if len(df_value) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    requisites = []\n",
    "    for text in df_value:\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        matches = re.findall(code_pattern, text)\n",
    "        requisites.extend(matches)\n",
    "\n",
    "    joined_matches = \" \".join(requisites)\n",
    "    return joined_matches\n",
    "\n",
    "\n",
    "def get_prerequisite_df(discipline_course_df):\n",
    "    prerequisite_dict = {\"id\": [], \"discipline_course_id\": [], \"prerequisite_discipline_id\": []}\n",
    "    discipline_course_dict = discipline_course_df.to_dict('records')\n",
    "\n",
    "    for discipline in discipline_course_dict:   \n",
    "        prerequisites = discipline['prerequisites'].split()\n",
    "         # create a dictionary where the keys are the codes and the values are the ids\n",
    "        id_map = discipline_df.set_index('code')['id'].to_dict()\n",
    "\n",
    "        # use the dictionary to map the codes to ids\n",
    "        discipline_ids = [id_map[code] for code in prerequisites if code in id_map]\n",
    "        if len(discipline_ids) > 0:\n",
    "            for prerequisite in discipline_ids:\n",
    "                prerequisite_dict['id'].append(uuid.uuid4())\n",
    "                prerequisite_dict['discipline_course_id'].append(discipline['id'])\n",
    "                prerequisite_dict['prerequisite_discipline_id'].append(prerequisite)\n",
    "   \n",
    "\n",
    "    prerequisite_df = pd.DataFrame(prerequisite_dict)\n",
    "    return prerequisite_df\n",
    "\n",
    "\n",
    "def get_discipline_course_tables(df, course_id, mandatory):\n",
    "    df = df.replace({r\"\\r\": \" \"}, regex=True)\n",
    "    df_struct = {\"id\": [], \"discipline_id\": [], \"period\": [], \"prerequisites\": []}\n",
    "    discipline_course_df = pd.DataFrame(data=df_struct)\n",
    "\n",
    "    iterIdx = -1\n",
    "\n",
    "    for idx, value in enumerate(df.values):\n",
    "        if idx == 0:\n",
    "            iterIdx = -1\n",
    "            discipline_course_df.at[0, \"id\"] = \"\"\n",
    "            discipline_course_df.at[0, \"discipline_id\"] = \"\"\n",
    "            discipline_course_df.at[0, \"period\"] = \"\"\n",
    "            discipline_course_df.at[0, \"prerequisites\"] = \"\"\n",
    "            continue\n",
    "\n",
    "        discipline_ids = discipline_df[discipline_df['code'] == value[0]]['id']\n",
    "        discipline_course_id = ''\n",
    "        discipline_id = ''\n",
    "\n",
    "        if(len(discipline_ids.values) > 0):\n",
    "            discipline_id = discipline_ids.values[0]\n",
    "        \n",
    "        if value[0]:\n",
    "            discipline_course_id = str(uuid.uuid4())\n",
    "\n",
    "        discipline_course_df.at[idx, \"id\"] = discipline_course_id\n",
    "        discipline_course_df.at[idx, \"discipline_id\"] = discipline_id\n",
    "        discipline_course_df.at[idx, \"period\"] = get_period(value, mandatory)\n",
    "        discipline_course_df.at[idx, \"prerequisites\"] = get_prerequisites(value)\n",
    "\n",
    "        if value[0] != \"\":\n",
    "            iterIdx = -1\n",
    "            continue\n",
    "\n",
    "        if iterIdx == -1:\n",
    "            iterIdx = idx - 1\n",
    "\n",
    "        discipline_course_df.loc[iterIdx, :] = [\n",
    "            f\"{item1} {item2}\".strip()\n",
    "            for item1, item2 in zip(\n",
    "                discipline_course_df.values[iterIdx], discipline_course_df.values[idx]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    discipline_course_df.drop(\n",
    "        discipline_course_df[discipline_course_df[\"discipline_id\"] == \"\"].index,\n",
    "        inplace=True,\n",
    "    )\n",
    "    discipline_course_df[\"mandatory\"] = mandatory\n",
    "    discipline_course_df[\"course_id\"] = course_id\n",
    "    discipline_course_df['period'] = discipline_course_df['period'].replace(\"\", 0)\n",
    "\n",
    "    prerequisite_df = pd.DataFrame()\n",
    "    if not discipline_course_df.empty:\n",
    "        prerequisite_df = get_prerequisite_df(discipline_course_df)\n",
    "\n",
    "    discipline_course_df.drop(\"prerequisites\", axis=1, inplace=True)\n",
    "    return discipline_course_df, prerequisite_df\n",
    "\n",
    "\n",
    "def scrape_table_from_pdf(pdf_path):\n",
    "    \n",
    "    # Read the table from the PDF file\n",
    "    df_list = tabula.read_pdf(pdf_path, pages=\"all\")\n",
    "\n",
    "    course_code = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    course_ids = course_df[course_df['code'] == course_code]['id']\n",
    "\n",
    "    \n",
    "    if(len(course_ids.values) == 0):\n",
    "        \n",
    "        return empty_discipline_course_df, empty_prerequisite_df\n",
    "\n",
    "    course_id = course_ids.values[0]\n",
    "    discipline_course_dfs = []\n",
    "    prerequisite_dfs = []\n",
    "\n",
    "    for df in df_list:\n",
    "        df.fillna(\"\", inplace=True)\n",
    "        header = df.columns.to_list()\n",
    "       \n",
    "        # Filter and select the desired columns based on the header\n",
    "        if \"DISCIPLINAS OBRIGATÓRIAS\" in header:\n",
    "            discipline_course_df, prerequisite_df = get_discipline_course_tables(\n",
    "                df, course_id, True\n",
    "            )\n",
    "            discipline_course_dfs.append(discipline_course_df)\n",
    "            prerequisite_dfs.append(prerequisite_df)\n",
    "\n",
    "        elif (\n",
    "            \"DISCIPLINAS ELETIVAS\" in header\n",
    "            or \"DISCIPLINAS ELETIVAS PRÉ-REQUISITO\" in header\n",
    "        ):\n",
    "            discipline_course_df, prerequisite_df = get_discipline_course_tables(\n",
    "                df, course_id, False\n",
    "            )\n",
    "            discipline_course_dfs.append(discipline_course_df)\n",
    "            prerequisite_dfs.append(prerequisite_df)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    combined_discipline_course_df = pd.concat(discipline_course_dfs, ignore_index=True)\n",
    "    combined_prerequisite_df = pd.concat(prerequisite_dfs, ignore_index=True)\n",
    "\n",
    "    discipline_course_df = combined_discipline_course_df[\n",
    "        combined_discipline_course_df[\"discipline_id\"].isin(discipline_df[\"id\"])\n",
    "    ]\n",
    "\n",
    "    prerequisite_df = combined_prerequisite_df\n",
    "    if not combined_prerequisite_df.empty:\n",
    "        prerequisite_df = combined_prerequisite_df[\n",
    "            combined_prerequisite_df[\"discipline_course_id\"].isin(\n",
    "                discipline_course_df[\"id\"]\n",
    "            )\n",
    "        ]\n",
    "    discipline_course_df[\"created_at\"] = datetime.now()\n",
    "    prerequisite_df[\"created_at\"] = datetime.now()\n",
    "\n",
    "    return discipline_course_df, prerequisite_df\n",
    "\n",
    "\n",
    "files = os.listdir(pdfs_folder_path)\n",
    "pdf_files = [\n",
    "    os.path.join(pdfs_folder_path, file) for file in files if file.endswith(\".pdf\")\n",
    "]\n",
    "\n",
    "for pdf_file in [\n",
    "    \"./courses_pdfs/engenharia-de-computacao.pdf\",\n",
    "    \"./courses_pdfs/engenharia-de-producao-jm.pdf\",\n",
    "    \"./courses_pdfs/sistemas-de-informacao.pdf\",\n",
    "    \"./courses_pdfs/engenharia-eletrica.pdf\",\n",
    "]:\n",
    "    print(f\"Buscando disciplinas de {pdf_file}\")\n",
    "    discipline_course_df, prerequisite_df = scrape_table_from_pdf(pdf_file)\n",
    "    \n",
    "    discipline_course_df = discipline_course_df[discipline_course_df['discipline_id'].isin(remaining_discipline_ids)]\n",
    "    store_df(discipline_course_df, 'discipline_course')\n",
    "    print(\"Disciplinas do curso armazenadas com sucesso!\")\n",
    "\n",
    "    remaining_discipline_course_ids = set(discipline_course_df['id'])\n",
    "    prerequisite_df = prerequisite_df[prerequisite_df['discipline_course_id'].isin(remaining_discipline_course_ids)]\n",
    "    store_df(prerequisite_df, 'prerequisite')\n",
    "    print(\"Prerequisitos armazenados com sucesso!\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
